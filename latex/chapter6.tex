 
    Sparse linear algebra is central to many scientific codes,
    yet compilers fail to optimize it well.
    Instead, programmers rely on library implementations
    that are hand optimized and can utilize accelerator hardware.
    This comes at a cost, however, as it ties programs into vendor specific
    software ecosystems and results in non-portable code.

    In this paper, we develop a new approach based on our {\em
    specification Language for implementers of Linear Algebra
    Computations} (LiLAC).
    Rather than requiring application developers to (re)write every
    program for a given library, the burden is shifted to a
    {\em one-off} description for the library implementer.
    The LiLAC-enabled compiler then uses this to
    incorporate library routines automatically.

    LiLAC provides automatic data marshaling, seamlessly maintaining
    state between calls as needed and minimizing data transfers.
    Appropriate places for library replacement are detected at the compiler
     intermediate representation level, making  our approach
    language independent.

    We evaluate on legacy large-scale scientific applications written in FORTRAN;
    standard benchmarks written in C/C++ and FORTRAN; and C++ graph analytics kernels.
    Across heterogeneous platforms, applications and data sets we show performance
    improvements of 1.1x to over 10x without any user intervention.


\section{Introduction}

Linear algebra is an important component of many compute intensive
applications.  While there are many compiler papers examining
automatic optimization of dense linear algebra, sparse codes
have received less attention.  Sparse algorithms are, however,
increasingly important as the basis for graph algorithms and data
analytics \cite{Kepner2015GraphsMA}.

Ideally, we would like compilers to automatically map dense and sparse-based
codes to heterogeneous compute platforms efficiently and with no user
intervention. However,  this has proven difficult.

Instead, we see the wide-scale provision of fast libraries
\cite{cusparse,clsparse,mkl}, often provided by hardware vendors themselves.
They provide excellent performance, but place the burden of code rewriting on
the application developer and are rarely portable across platforms.
Rewriting legacy applications can involve considerable effort, especially when
using hardware accelerators that require careful data marshaling.
In fact, the difficulty of efficient integration is a key impediment to the
wider use of accelerator libraries.
Furthermore, such source code modifications reduce the portability of the
program and require a commitment to specific hardware vendors, resulting in legacy
code bases that quickly become obsolete.

In this paper, we reexamine the way that compilers and libraries are used
to tackle the challenge of achieving full performance without any application
programmer effort.
Highly tuned and platform specific libraries are invariably the fastest
implementations available, therefore we use them as our building blocks.
We then develop a new specification language for implementers of such
libraries, the {\em specification Language for implementers of Linear Algebra
Computations} (LiLAC).

Using LiLAC, library implementers specify with a few lines of code,
{\em what} a library does and {\em how} it is invoked.  Our compiler
then determines where the library specification matches the user's
code and automatically rewrites the code to utilize library calls.

\noindent
{\bf LiLAC-What} is a high level language to describe sparse and dense linear
algebra computations.
The LiLAC compiler uses it to detect such functionality
in user applications at compiler intermediate representation level.
It is powerful enough to formulate linear algebra routines, yet remains
independent of compiler internals and is easy to understand and program.
\linebreak
\noindent
{\bf LiLAC-How} is a language to specify how parts of the LiLAC-What description
can be used for library invocations and how state can be retained in between
calls.
Our compiler uses this to automatically generate library call {\em harnesses} that
efficiently schedule memory transfers, execute setup code and handle hardware
context management.

Our approach is broadly applicable. To demonstrate its applicability
to legacy FORTRAN codes, we improved and extended the flang frontend
to LLVM and evaluated on a large-scale scientific application.
It also works on standard C/C++ and FORTRAN benchmark programs and C++ graph
\mbox{analytics} kernels. The LiLAC system achieves significant performance
improvement across heterogeneous platforms, from 1.1x to over 10x, without any
user intervention.
\begin{figure*}[t]
\includegraphics[width=\textwidth]{figures/lilac_overview.pdf}
\caption{LiLAC applied to NPB Conjugate Gradient:
         Code that matches the LiLAC-What specification is replaced with calls
         to a harness function. The harness is generated from a LiLAC-How
         specification to utilize Intel MKL.}
\label{motivationcode}
\end{figure*}

\section{Overview}
\label{sec:overview}

Consider the example in \autoref{motivationcode}.  In the top left
corner (1), we see unmodified application source code.  This is
{\em conjugate gradient} from the NAS-PB suite.  The program is written
in a straightforward manner and a naively compiled program would fail
to exploit the full potential of modern hardware.

In order to achieve good performance on Intel processors, we provide a
LiLAC specification of Intel MKL.
The LiLAC compiler (2) uses this to detect that the code in the framed loop is a
sparse matrix-vector product.
Instead of passing it on to the generic compiler backend, it replaces it with a
call to an auto-generated {\em harness} function  and captures the parameters of the computation
as function call arguments.
This is performed on optimized intermediate representation code (3)
and results in a program that is equivalent to the source code shown in the
bottom left (4).

LiLAC also automatically generates the corresponding harness as shown at
the right of the figure (5).
The resulting shared library is then linked with the application binary at
runtime, interfacing the underlying library implementation (6).

\begin{figure*}[t]
\includegraphics[width=\textwidth]{figures/whathowflow.pdf}
\caption{Overview of the LiLAC internals: On the left is the entire LiLAC
         program the library implementer must write. This results in a modified
         LiLAC-compiler in the bottom right that behaves as the shown in
         \autoref{motivationcode}.}
\label{motivationflow}
\end{figure*}

\subsection{Implementation Overview}

\autoref{motivationflow} provides more detail on the internals of
LiLAC.  On the left we can see the LiLAC specification provided by the
library implementer - just 16 lines of code.  It consists of a
{\em What} and a {\em How} part.  These two parts are processed by the
LiLAC system, eventually resulting in a runtime library and a modified
C/C++ compiler.

{\bf LiLAC-What} specifies the functionality that is provided by a library,
in this example {\em spmv-csr} (cf.\ \autoref{motivationcode}).
From this specification, a detection program that finds the computation in
normalized LLVM IR code is automatically generated and the harness interface
is determined.

{\bf LiLAC-How} specifies how the library, in this case Intel MKL, can be
invoked to perform the specified calculation.
This involves boilerplate code, but also advanced features, such as optimized
data transfers to accelerators.
In the last two lines, we can see how to efficiently compute the {\em columns}
variable with LiLAC.
It is not present in the {\em LiLAC-What} definition but is required by the MKL library. It  cannot be
captured statically and has to be computed at runtime using the values in the
{\em row\_ptr} array.
Using {\em Marshalling}, LiLAC automatically generates the harness
such that this is only recomputed if the values in {\em row\_ptr} change.

On the right of the figure we can see how the components generated from the
LiLAC specification are used to build the LiLAC-compiler.
Based on the LLVM infrastructure, it implements a transformation pass that
is executed after the normal optimization pipeline.
Using the generated detection function, it finds instances of the computation
and replaces them with calls to the specified harness interface.
Application binaries are dynamically linked to the harness library.

\section{What and How}

This section describes in more detail the two components of the LiLAC language.
LiLAC-What describes what a specific library does and LiLAC-How describes how
user code is bound to the underlying implementation.

\subsection{LiLAC-What: Functional Description}
At the heart of our approach is a simple language to specify sparse and dense
linear algebra operations.
This serves two purposes in our LiLAC system: Firstly, it is used to generate
a detection program for finding the computation in user code.
Secondly, it identifies the variables that are arguments to the library, thus
defining the harness interface.

The key challenge in the design of this language was to stay simple enough
to allow automatic generation of robust detection functionality, yet to be able
to capture interesting functionality.
Crucial for sparse linear algebra routines is capturing the many different
memory access patterns, the control flow on the other hand is very rigid.
This is reflected in the grammar as shown in \autoref{bnfgrammar}.

\subsection{Sparse Matrix Variations in LiLAC-What}
Sparse matrices can be stored in different formats.
In this section we introduce two of them and show how LiLAC-What can express
the corresponding computations.

\begin{figure}[p]
\input{latex/figure_lilacwhat}
\vspace{-1.5em}
\caption{Grammar of the LiLAC-What language}
\label{bnfgrammar}
\vspace{1.5em}
\begin{minipage}[b]{0.3\linewidth}
\includegraphics[width=0.9\linewidth]{figures/csrorder.png}
\vspace{0.04em}
\end{minipage}
\begin{minipage}[b]{0.65\linewidth}
\begin{align*}
\text{\bf val} =& \begin{bmatrix}
1\ \ 1\ \ 2\ \ 2\ \ \text{-}1\ \ 3\ \ 2\ \ 2\ \ \text{-}1\ \ 1\\
\end{bmatrix}\\
\text{\bf col\_ind} =& \begin{bmatrix}
0\ \ 2\ \ 1\ \ 3\ \ 1\ \ 2\ \ 3\ \ 3\ \ 2\ \ 4\\
\end{bmatrix}\\
\text{\bf row\_ptr} =& \begin{bmatrix}
0\ \ 2\ \ 4\ \ 7\ \ 8\ \ 10\\
\end{bmatrix}
\end{align*}
\end{minipage}
\caption{Compressed Sparse Row representation as used by the LiLAC-What example
         in \autoref{motivationcode}}
\label{csr_lilacwhat_fig}
\vspace{1.5em}
\centering
\begin{minipage}[b]{0.3\linewidth}
\includegraphics[width=0.9\linewidth]{figures/jdsorder.png}
\vspace{0.04em}
\end{minipage}
\begin{minipage}[b]{0.65\linewidth}
\footnotesize
\begin{align*}
\text{\bf perm} =& \begin{bmatrix}1\ \ 2\ \ 0\ \ 4\ \ 3\\\end{bmatrix}\\[-0.4em]
\text{\bf val} =& \begin{bmatrix}\text{-}1\ \ 1\ \ 2\ \ \text{-}1\ \ 2\ \ 3\ \ 1\ \ 2\ \ 1\ \ 2\\\end{bmatrix}\\[-0.4em]
\text{\bf col\_ind} =& \begin{bmatrix}1\ \ 0\ \ 1\ \ 2\ \ 3\ \ 2\ \ 2\ \ 3\ \ 4\ \ 3\\\end{bmatrix}\\[-0.4em]
\text{\bf jd\_ptr} =& \begin{bmatrix}0\ \ 5\ \ 9\ \ 10\\\end{bmatrix}\\[-0.4em]
\text{\bf nzcnt} =& \begin{bmatrix}3\ \ 2\ \ 2\ \ 2\ \ 1\end{bmatrix}
\end{align*}
\end{minipage}
\vspace{0.5em}
\hrule
\vspace{0.3em}
\includegraphics[width=\linewidth]{figures/spmvjdswhat.pdf}
\vspace{-1.2em}
\caption{Jagged Diagonal Storage in LiLAC-What}
\label{jds_lilacwhat_fig}
\end{figure}

\subsubsection{Compressed Sparse Row}
For Compressed Sparse Row (CSR) \cite{doi:10.1137/1.9780898718003}, all non-zero
entries are stored in a flat array \textbf{val}.
The \textbf{col\_ind} array stores the column position for each value.
Finally, the \textbf{row\_ptr} array stores the beginning of each row of the
matrix as an offset into the other two arrays.
The number of rows in the matrix is given directly by the length of the
\textbf{row\_ptr} array minus one, however the number of columns is not
explicitly stored.
In \autoref{csr_lilacwhat_fig}, a 5x5 matrix is shown represented in this
format, the LiLAC-What code is in the top left of \autoref{motivationflow}.

\subsubsection{Jagged Diagonal Storage}
For Jagged Diagonal Storage (JDS) \cite{doi:10.1137/0910073}, the rows of the
matrix are permuted such that the number of nonzeros  per row  decreases. The
permutation is stored in a vector \textbf{perm}, the number of nonzeros in
\textbf{nzcnt}.
The nonzero entries are then stored in an array \textbf{val} in the following
order: The first nonzero entry in each row, then the second nonzero entry in
each row etc.
The array \textbf{col\_ind} stores the column for each of the values and
\textbf{jd\_ptr} stores offsets into \textbf{val} and \textbf{col\_idx}.
The product of a sparse matrix in JDS format with a dense vector is specified 
in LiLAC-What at the bottom of \autoref{jds_lilacwhat_fig}.

\subsection{LiLAC-How}
\label{sec:lilachow}
Where LiLAC-What specifies the computations implemented by a library, LiLAC-How
describes how precisely library calls can be used to perform them.

The language was designed in order to support important existing libraries
such as cuSPARSE, clBLAS and Intel MKL.
The idiosyncrasies of these libraries require LiLAC-How specifications to be
built around boilerplate C++ code that manages the
construction of parameter structures, calling conventions etc.
However, we also wanted to make it as high-level as possible,
without sacrificing any performance.
In particular, LiLAC-How abstracts away memory transfers.

The result is a language that can be further divided into two interacting
components.
Firstly, it describes boilerplate code that is required for individual library
call invocations in a {\em harness}.
Secondly, it is used for data {\em marshaling} between the core program and the
library, which is particularly crucial for heterogeneous compute environments.
\autoref{lilacbnf2} shows the grammar specification of LiLAC-How.

\subsubsection{Individual Library Invocations}
We need to encapsulate the boilerplate code that any given library requires,
such as setup code, filling of parameter structures etc.
This part of the language is straightforward.

\paragraph{Harness}
The harness construct is the central way of telling the LiLAC system how a
library can be used to perform a computation that was specified in LiLAC-What.
As we can see at the top of \autoref{lilacbnf2}, a harness refers to a
LiLAC-What program by name and also has a name itself.
It is built around some C++ code, which can use all the variables from the
LiLAC-What program to connect with the surrounding program.
It also needs to specify the relevant C++ header files
that the underlying library requires.
Lastly, the harness can incorporate persistent state and utilize data
marshaling functionality.

\paragraph{Persistence}
Many libraries need setup and cleanup code, which is specified with the
keywords {\em BeforeFirstExecution} and {\em AfterLastExecution}.
These are used in combination with {\em PersistentVariables}, allowing state to
persist between harness invocations, e.g.\ to retain handlers to hardware
accelerators.

\paragraph{Example}
In \autoref{mklharness1}, we see a trivial LiLAC-What program for implementing
\texttt{spmv\_csr} with the Intel MKL library.
The actual call to the relevant library function is in line 16.
To prepare for that call, there is boilerplate code in lines 7--14 to fill
parameter structures.

Critically, there is an additional parameter required by the library that is
not part of the LiLAC-What specification: the number of columns, {\em cols}, in
the sparse matrix.
It is determined at runtime, in lines 2--5, leading to reduced performance.
We will avoid this with the data marshaling constructs in the next section.

\subsubsection{Data Marshaling}
Heterogeneous accelerators require data transfers to keep memory consistent
between host device and accelerator.
To achieve the best performance, these have to be minimized.

Importantly, unchanged data should never be copied again.
This is not trivial to achieve, as it requires dynamic checks.
LiLAC-How uses hardware memory protection to implement this with minimal
run time overhead in generated harnesses.

\begin{figure}[t]
\centering
\input{latex/figure_lilachow}
\vspace{-1.5em}
\caption{Grammar of LiLAC-How}
\label{lilacbnf2}
\vspace{0.8em}
\includegraphics[width=0.944\linewidth]{figures/harness2.pdf}
\\[-0.75em]
\caption{This LiLAC-What code implements CSR SPMV na\"ively with Intel MKL.
         Performance is degraded because of lines 2--5.
         \autoref{readablemax} will present a solution to this bottleneck.}
\vspace{2.em}
\label{mklharness1}
\end{figure}

\begin{figure}[t]
\centering
\includegraphics[width=0.944\linewidth]{figures/harness3.pdf}
\\[-0.75em]
\caption{LiLAC-How code to provide efficient automatic data marshaling between
         host and CUDA accelerator.}
\vspace{0.5em}
\label{cudaread}
\includegraphics[width=0.944\linewidth]{figures/harness4.pdf}
\\[-0.75em]
\caption{{\em INPUT} can also be used to specify data dependent computations
         that are only recalculated when required.}
\vspace{0.5em}
\label{readablemax}
\includegraphics[width=0.944\linewidth]{figures/harness1.pdf}
\\[-0.75em]
\caption{This LiLAC-What specification implements an efficient SPMV harness
  using cuSPARSE in only 25 lines of code.}
\label{spmvharness}
\end{figure}

This data {\em marshaling} comes in two flavors; INPUT and OUTPUT.
Both of these are bound to a range of memory in the harness.
The LiLAC-generated code then uses hardware memory protection to detect read and
write accesses to these memory ranges.
In the specification, the underlying array is available using the
identifiers {\tt in}, {\tt size}, and {\tt out}.

\subsubsection{Detailed Example}
In \autoref{cudaread}, LiLAC-How functionality is specified using the
\texttt{cudaMemcpy} function from NVIDIA CUDA.
It is used to copy data from the host to the accelerator.
Note that for this to work, it first needs to allocate memory of the
device using \texttt{cudaMalloc}, which is later freed with \texttt{cudaFree}.
\texttt{cudaMemcpy} is executed only when a value in the array changes,
resulting in minimal memory transfers.

We can use the same construct to efficiently compute values
such as the \texttt{cols} variable in \autoref{mklharness1}, as shown in
\autoref{readablemax}.
The optimized implementation is nearly identical to the code in
\autoref{mklharness1} lines 2-5, however instead of the concrete variable name
the reserved identifiers {\tt in}, {\tt size}, and {\tt out} are used.
\pagebreak

We can now use these in \autoref{spmvharness}, showing a CSR SPMV
LiLAC-How program for the cuSPARSE library.
A number of data marshaling variables are introduced in lines 12--17, that
automatically optimize both memory transfers and the computation of the
\texttt{cols} variable.
The core of the harness in lines 2--10 is again nothing more than 
library specific boilerplate C++ code.

\section{Implementation}
\label{sec:implementation}
The LiLAC system, as shown in \autoref{motivationflow} is entirely integrated
into the LLVM build system.
When LLVM is compiled, the LiLAC specification is parsed using a Python
program.
Based on the LiLAC-What and LiLAC-How sections, C++ code is generated that is
automatically incorporated into LLVM in further stages of the build process.

The result is an LLVM optimization pass that is available when linking LLVM
with the clang C/C++ compiler.
This pass performs the discovery of linear algebra code and the insertion of
harness calls.
Furthermore, the harness libraries themselves are built at compile time of LLVM,
using C++ code emitted from the LiLAC-How sections.

The two crucial implementation details are therefore the following:
Firstly, how automatic detection functionality in C++ is generated from the
LiLAC-What specifications.\linebreak
Secondly, how the LiLAC-How sections are used to generate fast C++
implementations of the specified library harnesses.

\subsection{LiLAC-What}
Once the LiLAC-What sections have been parsed, they are turned into C++
functionality that is used by the LiLAC LLVM pass to detect appropriate places
for harness calls.
Instead of performing this via syntax-level pattern matching, we use optimized
intermediate compiler representation.
The standard optimizations for \texttt{-O2} without vectorization and loop
unrolling are used.
This results in code in a normal form, which allows us to abstract away many
syntactic differences and programming languages.

The effect is demonstrated in \autoref{robustness}, which shows three
implementations of a dot product in different languages: C, C++ and FORTRAN.
After translating to LLVM IR and performing optimizations, the dot product is
recognized in the LiLAC system using the same LiLAC-What specification.

The exact detection algorithm works in two steps.
Firstly, the control flow skeleton is recognized.
This is simple, as the control flow that can be expressed in LiLAC-What is
limited, and we only need to detect loop nests of a certain depth.
After candidate loop nests have been identified, the index and loop range
calculations from LiLAC-What are mapped onto the LLVM IR nodes.
This is done via a backtracking search procedure that requires some careful
consideration in order to get robust results on implementation details of LLVM,
particularly for different ways of array indexing, pointer casts and integer
conversions.

\subsubsection{Backtracking Search Algorithm}
In order to match instances of LiLAC-What specifications in user programs,
the LLVM IR segments that match the corresponding control flow skeleton are
processed with a backtracking search algorithm.

All $\left<exp\right>$ expressions in the LiLAC-What program are identified.
These now have to be assigned instructions or other values from the LLVM IR
segment. The top-level $\left<exp\right>$ expressions that are used as limits or
iterators in $\left<range\right>$ expressions are easily connected with the
corresponding loop boundaries in the matched control flow structures.

The remaining expressions are successively assigned by backtracking.
Consider the example in \autoref{llvmexample}, which shows a candidate loop from
the LLVM IR generated from the C++ dot product code in \autoref{robustness}.
The iteration space is determined by loop analysis and this immediately allows us
to assign the LiLAC-What iterator and range in \autoref{backtrack}.
The LLVM IR instructions that correspond to \texttt{left[i]}, \texttt{left},
\texttt{right[i]}, \texttt{right} and \texttt{result} are then searched for one
by one.
When a partial solution fails, such as at the point when \texttt{right} is
assigned the same value as \texttt{left}, we backtrack.
If we cannot determine a solution this way, we discard the control flow
candidate.

\subsubsection{Code Replacement}
For each identified loop nest that matches a LiLAC-What specification, the code
is replaced with a harness call.
To minimize the invasiveness of our pass, this is performed as follows:
Firstly, a harness call is inserted directly before the loop.
The function call arguments are selected from the backtracking result and passed
to the harness.
Secondly, the LLVM instruction that stores the result of the computation or
passes it out of the loop as a phi node is removed.
The remainder of the loop nest is be removed automatically by dead code
elimination.

\begin{figure}[p]
\begin{lstlisting}[language=LiLAC,numbers=none]
COMPUTATION dotproduct
    result = sum(0 <= i < length) left[i] * right[i];
\end{lstlisting}
\begin{lstlisting}[language=C,numbers=none]
int i = 0;
while(i < N) {
    x += (*(A+i))*(*(B+i));
    i+=1; }
\end{lstlisting}
\vspace{-0.75em}
\begin{lstlisting}[language=C++,numbers=none]
for(int i = 0; i < vec_a.size(); i++)
    x += vec_a[i]*vec_b[i];
\end{lstlisting}
\vspace{-0.75em}
\begin{lstlisting}[language=FORTRAN,numbers=none]
DO I = 1, N, 1
    X = X + A(i)*B(i)
END DO
\end{lstlisting}
\vspace{-0.75em}
\caption{Syntactically different computations in C, C++ or FORTRAN are captured
         by one LiLAC-What specification.}
\label{robustness}
\vspace{1em}
\begin{lstlisting}[language=llvm,numbers=none]
; <label>:17:
  %18 = phi i64 [ 0, %10 ], [ %26, %17 ]
  %19 = phi double [ 0.0, %10 ], [ %25, %17 ]
  %20 = getelementptr double, double* %9, i64 %18
  %21 = load double, double* %20
  %22 = getelementptr double, double* %12
  %23 = load double, double* %22
  %24 = fmul double %21, %23
  %25 = fadd double %19, %24
  %26 = add nuw i64 %18, 1
  %27 = icmp ugt i64 %14, %26
  br i1 %27, label %17, label %15
\end{lstlisting}
\vspace{-0.75em}
\caption{Optimizations remove language specific features, the result is
         normalized LLVM IR. Control flow candidates for a match are easily
         determined with standard loop analysis.}
\label{llvmexample}
\vspace{1em}
\begin{tabular}{rcr|rcrr}
       &              &      & left[i]  & $\leftarrow$&                 \%21   &     \\
     i & $\leftarrow$ & \%18 & left     & $\leftarrow$&                  \%9   &     \\
length & $\leftarrow$ & \%14 & right[i] & $\leftarrow$&                 \%21   & \%23\\
       &              &      & right    & $\leftarrow$& \textcolor{red}{fail!} & \%12\\
       &              &      & result   & $\leftarrow$&                        & \%19\\
\end{tabular}
\caption{Control flow candidates contain iterator ranges directly (left),
         backtracking identifies the dot product by assigning the other
         LiLAC-What entities one by one (right).}
\label{backtrack}
\end{figure}


\begin{figure}[p]
\begin{lstlisting}
template<typename type_in, typename type_out>
void CudaRead_update(type_in* in, int size,
                     type_out& out) {
    cudaMemcpy(out, in, sizeof(type_in)*size,
               cudaMemcpyHostToDevice);
}
template<typename type_in, typename type_out>
void CudaRead_construct(int size, type_out& out) {
    cudaMalloc(&out, sizeof(type_in)*size);
}
template<typename type_in, typename type_out>
void CudaRead_destruct(int size, type_out& out) {
    cudaFree(out);
}
template<typename type_in, typename type_out>
using CudaRead = ReadObject<type_in, type_out,
    CudaRead_update<type_in,type_out>,
    CudaRead_construct<type_in,type_out>,
    CudaRead_destruct<type_in,type_out>>;
\end{lstlisting}
\vspace{-0.5em}
\caption{LiLAC uses code from \autoref{cudaread} to define three functions that
         specialize the ReadObject template, which uses \texttt{mprotect} for
         memory protection internally.}
\label{templatecode}
\end{figure}

\subsection{LiLAC-How}
To generate harnesses, LiLAC uses C++ templates.
The LiLAC-How syntax elements that take C++ code are used to generate
generic functions, and template parameter deduction inserts concrete types later.

Consider \autoref{templatecode}, generated from LiLAC-How code in
\autoref{cudaread}.
We see the correspondence between generated C++ and
LiLAC-How code in the three functions that contain the source
code specified in LiLAC-How.
These functions are used to specialize the {\em ReadObject} class template.
It guarantees the following properties using hardware memory protection:
\linebreak
\noindent
{\bf {\em construct}} is called before the first invocation and when
\texttt{in} or \texttt{size} change for consecutive harness invocations.
\linebreak
\noindent
{\bf {\em update}} is called after {\em construct}
and if any of the data in the array is changed between
consecutive harness invocations.
\linebreak
\noindent
{\bf {\em destruct}} is called in between consecutive {\em construct}
calls and before the program terminates.

% \paragraph{Multi-version profitability analysis}
% For most platforms there will be multiple libraries available
% implementing the same functionality. While we have moved the burden of
% using a DSL to accelerate from the user to the library vendor, we
% would also like to automate the selection of which library to use
% which may change over time and per application.

% Ideally, we would ask each library implementation to provide a model
% that predicts how good it will perform on certain data input. We would then
% ask each model its predicted performance and select the best. This would enable
% new libraries to be easily added.
% However, as such models are not currently available, we develop a simple
% prototype classifier for each platform, which given the 
% data input dynamically  selects the best library to use. We evaluate 
% this in the results section.

\subsection{FORTRAN}
Compatibility with FORTRAN was a key implementation hurdle. 
The LLVM frontend under active development, flang, is in an unfinished state and
produces unconventional LLVM IR code by default.
Significant additional work was required to normalize the IR code.
We developed normalization passes in LLVM to overcome the specific
shortcomings, enabling FORTRAN programs to be managed as easily as C/C++.

% flang utilizes the codebase from the PGI Fortran compiler.
% In effect, the PGI compiler parses the source code and generates intermediate
% representation code.
% This is then parsed and translated into LLVM IR code.
The problems that we encountered included: differing
indexing conventions requiring offsetting pointer variables 
on a byte granularity with untyped pointers;
incompatible intermediate representation types
where all parameters are passed in as \texttt{i64} pointers,
frequently necessitating a pointer type conversion followed
by a load from memory; obfuscated loops with additional induction variable that
counts down instead of up such that the standard LLVM \textbf{indvars} pass is
unable to merge the loop iterators.


%\paragraph{Implementation Status} 
%The LiLAC language, parser and scheme to detect and replace appropriate code
%with optimized calls to harness functions is fully implemented in the LLVM
%framework and available in the LLVM-based C/C++ compiler clang.
%The FORTRAN normalization code is implemented as an LLVM optimization pass.


\section{Experimental Setup}
\label{sec:experimentalsetup}
We wrote short  LiLAC  programs for a collection of
linear algebra libraries 
and applied our approach  to a chemical
simulation application, two graph analytics applications and a collection of
standard benchmark suites.

\vspace{0.25em}
\noindent
{\bf\em Libraries\ }
We selected four different libraries for sparse linear algebra
functions. These were: Intel MKL \cite{mkl}, Nvidia cuSPARSE \cite{cusparse},
clSPARSE \cite{clsparse} and SparseX \cite{sparsex}. MKL is a general-purpose
mathematical library designed to provide easy-to-integrate performance
primitives, while clSPARSE and cuSPARSE are OpenCL and CUDA implementations of
sparse linear algebra designed to be executed on the GPU and SparseX uses an
auto-tuning model and code generation to optimize sparse operations on
particular matrices.

\vspace{0.25em}
\noindent
{\bf\em Applications\ }
To evaluate the impact of LiLAC in a real world context, we used the
\textsc{pathsample} physical chemistry simulation suite, a large FORTRAN legacy
application \cite{doi:10.1080/00268970210162691} consisting of over 40,000 lines
of code.
Recent work shows that applications in this area are amenable to acceleration
using sparse linear algebra techniques \cite{SUTHERLANDCASH2017288}, and
\textsc{pathsample} provides a useful example of this.
We also evaluated two modern C++ graph analytics kernels (BFS and PageRank
\cite{demetrescu2009shortest,Beamer2015GAP}).
\textsc{pathsample} was run in two different modes and three different levels of
pruning, in each case using a system of 38 atoms \cite{doi:10.1063/1.478595}
commonly used to evaluate applications in this domain.
The graph kernels were run against 10 matrices from the University of Florida's
sparse matrix collection \cite{Davis:2011:UFS:2049662.2049663}, with sizes
between 300K and 80M non-zero elements.

\vspace{0.25em}
\noindent
For completeness and validation that our LiLAC-generated implementations were
correct, we also applied our technique to sparse codes from standard benchmark
suites: CG from the NAS parallel benchmarks \cite{Bailey1991NPB}, spmv from
Parboil \cite{Stratton2018} and the Netlib sparse benchmark suites
\cite{Dongarra2001}.
Each benchmark suite was run using their supplied inputs.

\paragraph{Platforms}

We evaluated our approach across 
%5
3  different machines with varying hardware
performance and software availability. Each one was only compatible with a
subset of our LiLAC-generated implementations---a summary of these machines is
given in \autoref{tab:hardware}.

%% MOB assume we have only 3 machines?????
% intel0 = monaco
% intel1 = avus
% intel2 = spa
% amd0 = michel
% amd1 = bob

\makeatletter
\newcommand{\IntelBig}{\bBigg@{5}}
\newcommand{\AMDBig}{\bBigg@{3}}
\newcommand{\AMDSmall}{\bBigg@{2}}
\makeatother

\begin{table}[t]
  \begin{tabularx}{\columnwidth}{cXl}
    \textbf{Name} & \textbf{Hardware} & \textbf{Libraries} \\
    \toprule
    \toprule
    Intel-0 & 2$\times$ Intel Xeon E5-2620 \newline Nvidia Tesla K20 GPU
           & \multirow{4}{*}[-0.3em]{
                \begin{tabular}{l} 
                  MKL \\ 
                  cuSPARSE \\
                  clSPARSE \\
                  SparseX
                \end{tabular}
              }\\[1.5em]
    Intel-1 & Intel Core i7-8700K \newline Nvidia GTX 1080 GPU 
           & \\[.8em]
    \midrule
    AMD & AMD A10-7850K \newline AMD Radeon R7 iGPU \newline Nvidia Titan X GPU 
         & \multirow{3}{*}{
              \begin{tabular}{l}
                cuSPARSE \\
                clSPARSE $\times 2$\\
                SparseX
              \end{tabular}
            }\\[1.8em]
  \end{tabularx}
\vspace{0.5em}
  \caption{Evaluated platforms and library harnesses;
           AMD-0 supports clSPARSE on both its internal and its external GPU.}
  \label{tab:hardware}
\end{table}

% \begin{enumerate}
%   \item Does our approach reliably speed up the execution of code across a
%     variety of platforms with different hardware and software availability?
%   \item Are the speedups we achieve automatically comparable to those achievable
%     using best-in-class manual approaches?
%   \item How important are the lazy computation elements of our approach to the
%     performance gains achieved?
%   \item Can the fastest implementation available on a particular platform be
%     accurately and efficiently chosen at runtime?
%   \item How effective is our approach at discovering instances of code that can
%     be run using accelerated implementations?
% \end{enumerate}

\section{Results}
\label{sec:results}

We show that across a variety of hardware and software platforms, LiLAC can
speed up real-world applications.
We present raw performance impact first, then we analyze two intermediate
metrics: reliability of linear algebra discovery and effectiveness of memory
transfer optimizations.

\subsection{Performance}

\begin{figure*}[t]
  \centering
  \includegraphics[width=2.1\columnwidth,height=0.5\columnwidth]{figures/baseline.pdf}
  \includegraphics[width=2.1\columnwidth,height=0.5\columnwidth]{figures/baseline_bench.pdf}
\\[-0.75em]
  \caption{Evaluation on real-world application code and well-known benchmark
          suites:
           Bars show geometric mean speedup of best-performing LiLAC harness across the
           set of input examples for each benchmark and platform. }
  \label{spmv_app_perf}
\end{figure*}

The speedups that LiLAC achieves on real applications as well as benchmarks are
shown in \autoref{spmv_app_perf}.
They range from $1.1$--$3\times$ on the scientific application codes to
12$\times$ on well-known sparse benchmark programs.

On the \textsc{pathsample} applications (PFold and NGT), we measured
consistent speedups of approximately 50$\%$ and 10$\%$ respectively across
all 3 platforms.
For large applications, Amdahl's law is a severe limitation for
approaches like ours --- other parts of the applications dominate execution
times when linear algebra is accelerated.

PageRank requires a large number of SPMV calls using the same input matrix to
iterate until convergence.
The GPU implementations running on AMD and Intel-1 are able to take advantage of
data remaining in memory.
The larger number of CPU cores and slower GPU available on \mbox{Intel-0} make
MKL its best-performing implementation.
CPU implementations perform best on BFS by avoiding memory copies entirely
--- on AMD, SparseX outperforms GPU implementations.

On standard sparse linear algebra benchmarks, LiLAC achieves speedups of up to
$12\times$.
The impact is independent of the source language, as the C and FORTRAN versions
of the Netlib benchmark demonstrate.
LiLAC is able to achieve consistent, useful speedups across a variety of
hardware configurations.


\autoref{fig:performance-distribution} demonstrates that achieving good
performance independent of hardware platform is no small feat.
It shows the distribution of speedups on the NPB-CG benchmark across different
machines, problem sizes and linear algebra implementation.
Additional performance data is in \autoref{tab:perf_data}.
The best-performing implementation varies considerably, depending on
characteristics of the problem in question.
No accelerator library performs well reliably, each harness outperforms
any other harness on some combination of data set and platform.
clSPARSE on the iGPU of AMD is the only harness that is consistently
outperformed.

\begin{table*}[t]
  \centering
  \footnotesize
  \begin{tabular}{ll|ccc|ccc|ccc|ccc}
    \multirow{2}{*}{\textbf{Platform}} &
    \multirow{2}{*}{\textbf{Implementation}} &
    \multicolumn{3}{c}{\textbf{PFold}} & \multicolumn{3}{c}{\textbf{NGT}} &
    \multicolumn{3}{c}{\textbf{PageRank}} & \multicolumn{3}{c}{\textbf{BFS}} \\[-0.3em]
    & & \hspace{0.8em}L0\hspace{0.8em} & \hspace{0.8em}L1\hspace{0.8em} & \hspace{0.8em}L2\hspace{0.8em}
      & \hspace{0.8em}L0\hspace{0.8em} & \hspace{0.8em}L1\hspace{0.8em} & \hspace{0.8em}L2\hspace{0.8em}
      & \hspace{0.35em}Erdos\hspace{0.35em} & LJ-2008 & \hspace{0.35em}Road\hspace{0.35em}
      & \hspace{0.35em}Erdos\hspace{0.35em} & LJ-2008 & \hspace{0.35em}Road\hspace{0.35em} \\
    \hline
    \hline
    \multirow{3}{*}{Intel-0} 
    & MKL & 2.88 & 2.46 & 1.00 & 1.18 & 1.18 & 1.18 & 1.25 & 2.93 & 1.72 & 2.50 & 1.06 & 1.05 \\[-0.3em]
    & cuSPARSE & 0.75 & 0.60 & 0.45 & 0.66 & 0.66 & 0.66 & 1.39 & 1.00 & 3.32 & 0.87 & 1.74 & 1.28 \\[-0.3em]
    & clSPARSE & 0.90 & 0.75 & 0.46 & 0.81 & 0.79 & 0.78 & 1.24 & 0.95 & 2.24 & 0.13 & 1.45 & 0.07 \\[-0.3em]
    & SparseX & - & - & - & - & - & - & - & - & - & 1.19 & - & - \\
    \hline
    \multirow{3}{*}{Intel-1}
    & MKL & 2.70 & 2.43 & 1.01 & 1.20 & 1.20 & 1.19 & 1.63 & 1.03 & 2.26 & 1.06 & 2.09 & 1.27 \\[-0.3em]
    & cuSPARSE & 0.48 & 0.41 & 0.30 & 0.68 & 0.69 & 0.68 & 1.59 & 0.87 & 4.44 & 1.01 & 1.83 & 1.63 \\[-0.3em]
    & clSPARSE & 1.00 & 1.00 & 1.00 & 1.00 & 1.02 & 1.00 & 1.50 & 0.87 & 3.46 & 0.23 & 1.81 & 0.13 \\[-0.3em]
    & SparseX & - & - & - & - & - & - & - & - & - & 1.25 & - & - \\
    \hline
    \multirow{4}{*}{AMD}
    & cuSPARSE & 1.38 & 1.18 & 0.67 & 0.69 & 0.69 & 0.70 & 3.44 & 1.18 & 9.97 & 1.62 & 6.55 & 1.96 \\[-0.3em]
    & clSPARSE (eGPU) & 2.17 & 1.82 & 1.22 & 1.16 & 1.16 & 1.16 & 3.08 & 1.24 & 6.06 & 0.50 & 11.03 & 0.24 \\[-0.3em]
    & clSPARSE (iGPU) & 2.03 & 1.78 & 1.03 & 0.90 & 0.90 & 0.90 & 3.26 & 1.31 & 4.05 & 0.14 & 4.17 & 0.05 \\[-0.3em]
    & SparseX & - & - & - & - & - & - & - & - & - & 1.93 & - & - \\
  \end{tabular}
\vspace{0.5em}
  \caption{LiLAC speedups on each platform, across different applications and
  problem sizes.
  SparseX demonstrated promising performance on some applications, but we were
  unable to evaluate on every relevant instance due to instability.}
  \label{tab:perf_data}
\vspace{-2em}
\end{table*}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth,height=0.67\columnwidth]{figures/distribution.pdf}
\\[-0.75em]
  \caption{Distribution of speedups achieved by LiLAC on the NPB-CG benchmark.
    Each column of points shows the speedup achieved by each implementation
    available on a platform for a particular problem size. Data is sorted along
  the $x$-axis by the best speedup in that column.}
  \label{fig:performance-distribution}
\end{figure}

We verify that LiLAC can reach near-optimal performance, despite using general
and portable harnesses, by comparing the achieved speedups with the performance
of reference implementations.
This was possible on the NPB and Parboil benchmarks, where expert hand
crafted version are available that achieve close to peak performance on
heterogeneous accelerators.


\autoref{tab:lilac-linesofcode} shows our results from these experiments.
For context, we also measure application programmer effort for peak performance,
which is substantial, requiring hundreds of lines of carefully crafted
high performance OpenCL code.
On the NPB-CG benchmark, we achieve $\sim 3\times$ speedup,
while the expert implementation is approximately 3$\times$ faster than LiLAC.
This is partly due to Amdahl's law --- the benchmark also performs operations
other than sparse matrix-vector multiplication and the expert implementation is
a complete rewrite that performs all these operations on the GPU.
On Parboil SPMV, the difference between an expert and LiLAC is only
1.07$\times$.

\begin{figure}[t]
  \centering
  \includegraphics[width=0.9\columnwidth,height=0.5\columnwidth]{figures/expert.pdf}
\\[0.5em]
  \begin{tabular}{lrr}
    \multirow{2}{*}{\textbf{Benchmark}} & \multicolumn{2}{c}{\textbf{Modified LoC}} \\
    & LiLAC & Expert \\
    \toprule
    \toprule
    NPB          & 0 (44) & 1948 \\
    Parboil SPMV & 0 (44) & 261
  \end{tabular}
\\[0.45em]
  \caption{LiLAC vs Expert: We achieve good performance with no application
           programmer effort (measured as required LoC change).
           LiLAC code to be written by library developers is in parentheses.
           Amdahl's Law limits our impact on NPB.
}
  \label{tab:lilac-linesofcode}
\end{figure}

After moving the burden of targeting accelerators from the user to the
library vendor with LiLAC, we would also like to automate the selection of which
library to use.
This may change over time and per application, as we saw in
\autoref{fig:performance-distribution}.
We have experimented with simple classifiers for each platform, that dynamically
select the best library given the data input.
This was straightforward to achieve for our problem space, but more data is
needed for a meaningful evaluation, and we leave it to future work.


\subsection{Effectiveness of Data Marshaling}
Our implementation of LiLAC relies on a non-trivial data marshaling system that
prevents redundant computations and memory transfers. We present performance
results that show the importance and effectiveness of this system.

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth,height=0.67\columnwidth]{figures/marshall.pdf}
\\[-0.75em]
  \caption{LiLAC vs. na\"ive library calls without harnesses.
           Avoiding memory transfers is necessary for performance.}
  \label{fig:transfer-performance}
\end{figure}

We repeated our experiments, using the best-performing implementations from
\autoref{spmv_app_perf}.
Instead of using our data marshaling scheme, we transfer memory naively for
each accelerator invocation.
We then measured the performance advantage that our harness system gives us over
this naive approach, results are in \autoref{fig:transfer-performance}.
The GPU implementations received speedups of 1.4--3.5$\times$ and SparseX was
sped up by over $25\times$ (because it performs an internal matrix tuning phase
that is far more expensive than a memory copy).
These speedups are large enough that in each case, the application would in fact
have performed worse than their sequential baselines without performing data
marshaling.

\begin{table}[b]
\centering
\caption{Sparsity does not fit the polyhedral model, Intel compilers fail to
         parallelize and Polly is not available for FORTRAN.
         Only LiLAC detects sparse linear algebra reliably.}
\label{compareiccpolly}
\vspace{-0.5em}
\small
\begin{tabular}{l|c|c|c}
{\bf Benchmark}      & {\bf LiLAC}    & {\bf Polly}   & {\bf Intel icc/ifort} \\
\hline
\hline
PFold          & CSR & - & parallel dependence \\[-0.3em]
NGT            & CSR & - & parallel dependence \\[-0.3em]
Parboil-SPMV   & JDS & no SCoP & parallel dependence \\[-0.3em]
BFS            & CSR & no SCoP & parallel dependence \\[-0.3em]
NPB-CG         & CSR & - & parallel dependence \\[-0.3em]
PageRank       & CSR & no SCoP & parallel dependence \\[-0.3em]
Netlib C       & CSR & no SCoP & parallel dependence \\[-0.3em]
Netlib Fortran & CSR & - & parallel dependence \\
\end{tabular}
\end{table}

\subsection{Reliability of Discovery}
To achieve performance impact, LiLAC needs to first reliably detect linear
algebra computations, independent of coding style and source programming
language.
Previous results already demonstrated that this works reliably and
\autoref{compareiccpolly} \mbox{reiterates} this.
Established approaches, like the polyhedral model, are unable to model sparse
linear algebra. We verified with the Polly compiler.
Similarly, the Intel icc and ifort compilers fail to auto-parallelize, as they
cannot reason about sparsity and have to assume additional dependencies where
sparse accesses occur.



% \subsection{Portability}

% \emph{Should we make the point here that we make the performance of these
%   applications more portable - shared library "performance" component rather
% than hand-coded platform-specific code? Show that on some platforms one version
% is the best / different on others - no one size fits all solution so show that
% we can transfer performance much more easily - e.g. MKL might be fastest on
% Intel with 24 cores but it won't even run on AMD where CUDA is fastest}


\section{Related Work}
\label{sec:relatedwork}
\paragraph{Compiler centric linear algebra optimization} Compiler
management of indirect memory accesses was first examined using an
inspector-executor model for distributed-memory machines
\cite{Baxter:1989:RPS:72935.72967}. Here the location of read data was
discovered at runtime and appropriate communication inserted.  Later
work was focused on efficient runtime dependence analysis and the
parallelization of more general
programs\cite{pottenger1995idiom,fisher1994parallelizing,
rauchwerger1999lrpd,suganuma1996detection}.  However, the performance
achieved by these approaches is modest due to runtime 
overhead and falls well short of library performance.

%\paragraph{Polyhedral compiler approaches}
The polyhedral model is a well  established compiler  approach  for modeling data dependencies.
\cite{redon1994scheduling, jouvelot1989unified,
chi1997optimizing, gupta2006simplifying, stock2014framework}.
Such an approach has been implemented in optimizing compilers, such as the Polly extensions to LLVM
\cite{Doerfert2015Polly}. %, but these struggle to scale with code complexity.
% The difficulty in automatically detecting reductions has led to language or
% annotation based approaches where it is the user's responsibility to mark
% reductions in the program \cite{deitz2002high}.
% Another such annotation based approach is described in
% \cite{Reddy2016Reduction}, based on the Platform-Neutral Compute Intermediate
% Language (\cite{baghdadi2015PENCIL}).
% Our approach requires no such anotation effort by application programmers.
Recent work has extended the polyhedral model beyond affine programs to some forms of sparsity with the
PENCIL extensions \cite{7429301}.
These can be used to model important features of sparse linear algebra, such as
counted loops \cite{Zhao:2018:PCF:3178372.3179509}, meaning loops with dynamic,
memory dependent bounds but statically known strides.
Such loops are central to sparse linear algebra.
It uses the PPCG compiler \cite{Verdoolaege:2013:PPC:2400682.2400713} to
automatically detect relevant code regions, but it relies on well behaved C code
with all arrays declared in variable-length C99 array syntax.
Unfortunately such restrictions prevent application to real world programs;
none of our benchmarks or data sets have this structure.

\paragraph{Compiler detection} There has been previous work on
detecting code structures in compilers using constraint programming.
Early work was based on abstract computation graphs
\cite{pinter1994program}, but more recent approaches have used real
compiler intermediate code and made connections to the polyhedral
model \cite{Ginsbach:2018:CDS:3178372.3179515}.

In \cite{Ginsbach:2018:AML:3173162.3173182} they implement a method that operates on SSA
intermediate representation.
%It is based on the Idiom Description Language (IDL), a domain specific
%constraint programming language.
%There are several fundamental differences to our approach:
%Firstly, IDL
It uses a  general-purpose low level constraint programming language  aimed at
compiler engineers. % , not library implementers.
%It is difficult to use and
% requires a deep understanding of compiler internals.
%Secondly,
The %methodology of the
paper focuses  on code detection, with library calls inserted by hand.
%the
%necessary replacement functionality is then implemented manually.
It is performed naively without the use of harnesses and the results show
significant performance degradation due to the redundant memory transfers that
have to be amended manually.
Other advanced approaches to extracting higher
level structures from assembly and well structured FORTRAN code
involve temporal logic \cite{Mendis2015Helium, Kamil2016Verified}.
These approaches tend to focus on a more restricted set of
computations (dense memory access).
While this allows formal reasoning about correctness, is too restrictive to
model sparse linear algebra.


% Domain specific languages
\paragraph{Domain Specific Languages}
There have been multiple domain specific libraries proposed to formulate linear
algebra computations.
% targeted at application programmers rather than library implementors
Many of these contain some degree of autotuning functionality to achieve good
performance across different platforms
%%The Delite
\cite{Sujeeth:2014:DCA:2601432.2584665}.
%language can be used as an
%%intermediate representation to construct domain specific languages for
%%heterogeneous platforms.
%%However, the approach is tightly integrated with the Scala programming language
%%and does not offer a readily available end-to-end solution.
Halide %programming language
\cite{Ragan-Kelley:2013:HLC:2499370.2462176}
was designed for image processing.
%but also allows the formulation
%of matrix multiplications and other computations based on reductions
\cite{Suriana:2017:PAR:3049832.3049863}.
Its core design decision is the scheduling model that allows the separation of
the computation schedule and the actual computation.
There has been work on automatically tuning the schedules
\cite{Mullapudi:2016:ASH:2897824.2925952} but in general the computational
burden is put on the application programmer.
%%The LIFT programming language \cite{Steuwer:2015:GPP:2858949.2784754} provides
%%constructs from functional programming to implement data-parallel algorithms and
%%operations.
%%It is particularly suitable for dense linear algebra applications
%%\cite{Steuwer:2016:MMB:2968455.2968521} but extensions to sparsity exist
%%\cite{b5f556d505d746109608f8db3cbce4ac}.
The MILK programming model \cite{Kiriansky:2016:OIM:2967938.2967948} extends C++
with pragmas to annotate indirect memory accesses.
This allows low level optimizations that are applicable to sparse linear
algebra.
%The authors
%report performance gains of up to 3x.
However, the approach is unable to utilize
the much greater potential of heterogeneous compute and requires detailed
programmer intervention.

\paragraph{Libraries}
The most established way of encapsulating fast linear algebra routines is via
numeric libraries, generally based on the BLAS interface
\cite{2002:USB:567806.567807}.
These are generally very fast on specific hardware platforms, but require
application programmer effort and offer little performance portability.
Implementations of dense linear algebra are available for most suitable hardware
platforms, such as cuBLAS \cite{cublas} for NVIDIA GPUs, clBLAS \cite{clblas}
for AMD GPUs and the Intel MKL library \cite{mkl} for Intel CPUs and
accelerators.

Fast implementations of sparse linear algebra are fewer, but they exist for the
most important platforms, including cuSPARSE \cite{cusparse} and clSPARSE
\cite{clsparse}.
There have been several BLAS implementations that attempt platform independent
acceleration and heterogeneous compute \cite{Wang:2016:BHP:2925426.2926256,
10.1007/978-3-319-64203-1_33, Diego2017Multi}. 


%\paragraph{Graphs as sparse linear algebra}
%Graph processing is an important computational domain, especially in the context
%of large social media graphs \cite{5470687, 6408680}.
%The duality between graph processing and sparse linear algebra is well studied
%\cite{doi:10.1137/1.9780898719918} and has lead to the development of the
%GraphBLAS interface standard \cite{6670338,7761646}.
%GraphBLAS attempts to define a standard set of building blocks for graph
%algorithms that use the language of linear algebra.

\paragraph{CPU-GPU data transfer optimizations}
Data transfers between CPU and GPU have been studied extensively as an important
bottleneck for parallelization efforts.
Previous work \cite{Jablin:2011:ACC:1993316.1993516} established a system for
automatic management of CPU-GPU communication.
The authors of \cite{Lee:2009:OGC:1594835.1504194} implemented a system to
move OpenMP code to GPUs, optimizing data transfers using data flow analysis.
However, this approach performs a direct translation, not optimizing the code
for the specific performance characteristics of GPUs.


%% EArly scalar detection sc
%Discovering and exploiting scalar reductions in programs has been
%studied for many years based on dependence analysis and idiom detection
% \cite{pottenger1995idiom,suganuma1996detection,fisher1994parallelizing}.
%Early work focused on well structured Fortran and
%paid little attention to compiler-based detection, a notable exception being. 
%\cite{suganuma1996detection}. 
%In \cite{rauchwerger1999lrpd}, the authors went beyond previous static
% approaches and developed  a dynamic test to speculatively exploit
% reduction parallelism.
%%%Early ploy detection
%Alongside this data dependence based approach, there has also been a
% large body of work exploring mapping of reductions in a
% polyhedral setting \cite{redon1994scheduling, jouvelot1989unified}
%
%%% Expoitation of genearlise reductiosns 
% The treatment of
%more general reduction operations has received  less attention
%Work has focused on exploitation rather than discovery
%\cite{gutierrez2003optimization,gutierrez2008analytical, Gutierrez:2000}, examining trade-offs in implementation \cite{yu2006adaptive}
% or exploitation of novel hardware \cite{ravi2010compiler,Huo2011HiPC}
%In \cite{das2010experiences}, they use dynamic profile analysis to
%guide manual analysis and show there is potential for finding
%generalized reductions. In \cite{kim2012dynamic} they explore the use
%of dynamic analysis further, but state that detecting reductions on arrays is
%challenging.
%
%
%
%%% LLVM out there \cite{lattner2004llvm}
%%% What NAS:\cite{seo2011performance}
%
%%% Vaguely related C;
%
%
%%% New polyhedral approaches
%
%More recently, extensions
%to the polyhedral framework have been proposed, allowing  it to capture
%reduction computations \cite{chi1997optimizing, gupta2006simplifying,
%stock2014framework} Such efforts are described
%in \cite{Doerfert2015Polly}.  The authors discuss and implement a
%reduction-enabled scheduling approach as part of Polly and use the
%Polybench benchmark suite to evaluate it, achieving speedups of up to
%2.21x. However as shown in our evaluation section, such schemes are
%fragile in the presence of non static control flow.
%
%%% Language Poly and non-polly
% The difficulty in automatically detecting
%reductions has led to language or annotation based approaches where it
%is the user's responsibility to mark reductions in the
%program \cite{deitz2002high}.
%%% Another approach to incorporate the reduction idiom into the Polyhedral Framework using annotations is described in
%An annotation approach is described in 
%\cite{Reddy2016Reduction}, based on the Platform-Neutral Compute Intermediate Language (\cite{baghdadi2015PENCIL}).
%This used the code generator
%in (\cite{Verdoolaege2013Polyhedral}) to generate CUDA and OpenCL code for multiple compute platforms.
%
%
%
%%% New dynamic approaches
%There has also been recent work following on
%from \cite{rauchwerger1999lrpd} in using more aggressive
%speculation and dynamic analysis \cite{aguilar2015unified} to exploit reduction parallelism.
%The authors of \cite{Han2010Speculative} present an approach for the parallelization of a wide class of scalar reductions.
%They start from the observation that many reductions in real benchmark programs are not detected by current static analysis approaches.
%They propose a hardware assisted speculative parallelization approach for likely runtime reductions, denominated `partial reduction variables'.
%Candidates for speculative parallelization are determined by searching for update-chains in the data flow graph.
%The approach is evaluated on some of the SPEC2000 benchmarks using a simulator.
%They achieve up to $46\%$ speedup by including speculative reductions.
%This approach
%based on update chains in the dependence graph requires hardware
%speculation support to check dependences but is unable to detect
%histogram reductions.
%
%Privateer introduced in \cite{Johnson2012Speculative}, is a complex
%system featuring compiler support and a runtime to enable speculative
%parallelization.  The core approach is the privatization of memory
%for each thread and an exception mechanism with recovery routines for
%accesses that violate parallelism.  The authors explicitly allow for
%reduction parallelism that involves only a single scalar associative
%and commutative operator.  The implementation approach is to first
%profile the program for hot loops and then to classify all variables
%accessed in those loops into different groups.  A transformation pass
%then identifies corresponding \texttt{malloc} and \texttt{free} calls
%and replaces them by thread local allocations.  In a similar way
%all\texttt{load} and \texttt{store} instructions are replaced by local
%accesses.  At runtime, the system uses manual page table switching and
%memory protection to minimize runtime overhead.  The evaluation is
%done on a limited set of five benchmark programs, yielding a geometric
%mean speedup of 11.4x on a 24 core machine.  The runtime overhead on
%these five programs varies between $<1\%$ and $>50\%$.  Despite this
%complexity they only exploit simple scalar reductions.
%
%In \cite{Andion2015Compilation}, it describes a compiler based
%parallelization approach for heterogeneous computing that is based on
%an idiomatic intermediate representation called KIR.  This
%intermediate representation is based on the concept
%of \mbox{diKiernels}, which constitute algorithmic building blocks and
%are used to automatically generate OpenMP and OpenHMPP code.  The
%authors propose a system that detects diKernels in conventional
%compiler IR and concatenates them to form contiguous sections of KIR.
%Individual examples of diKernels are scalar reductions and irregular
%assignments. It is not clear how such an approach would work on general
%'C' programs.
%


\section{Conclusion}
\label{sec:conclusion}
% Sparse and dense linear algebra are critical workloads for many important
% established applications and will only gain more significance with emerging
% domains such as deep learning and AI.

% Past experience has shown that acceleration solutions that require even limited
% modifications of legacy source code hinder mainstream adoption.
% Hence, the providion of custom APIs for new accelerator hardware is insufficient
% to penetrate scientific computing outside of elite projects.
% At the same time, entirely compiler based solution have failed to scale and
% perform.

% We have demonstrated that our approach of compiler based detection coupled with
% library based acceleration manages to combine the advantages of both, achieving
% the full performance without requiring programmer intervention.
% We showed that this scales to large scientific codes across multiple programming
% languages.

This paper has presented LiLAC, a language and compiler that enables existing
code bases to exploit sparse (and dense) linear algebra accelerator libraries.
No effort is required from the application programmer.
Instead, the library implementer provides a few lines of specification, which
LiLAC uses to  automatically and efficiently matches  user code to
underlying high performance libraries.

We demonstrated this approach on  C, C++ and FORTRAN benchmarks and
legacy applications and shown significant performance improvement across
platforms and data sets.
Many language features of the LiLAC language could be repurposed for libraries
beyond linear algebra.
In future work, we will investigate how our framework could be adapted to other
application domains, enabling effort free access to an even larger set of
accelerator libraries.

