
    Four areas of research are of particular relevance to this thesis:
    {\bf Constraint programming and specification languages} are central to the
    introduced methodology.
    The relevant literature includes the research into constraint programming in
    the context of program analysis and the design of specification languages.
    The survey of previous approaches to
    {\bf compiler analysis and auto-parallelisation}
    establishes the baselines for the later evaluation sections.
    Related work on {\bf heterogeneous computing} motivates the proposed
    approaches, by presenting the plethora of other programming paradigms to
    overcome the specific challenges of emerging hardware.
    Lastly, the diverse research landscape around concepts related to
    {\bf computational idioms} puts the algorithmic structures that are detected
    in later chapters of this thesis into context.

\section{Constraint Programming and Specification Languages}

    Declarative Languages, constraint programming, and the application of
    constraints to program analysis problems are well-established in the
    literature.
    Previous work covers query languages, logic programming, applications to
    software security and formal verification, model checking and SMT,
    but also more compiler-centric data flow analysis and type inference
    problems.
    The limited scope of this section requires a focus on work that is
    particularly relevant to this thesis.

    For this research, constraint programming is most interesting within the
    context of research fields such as program analysis and model checking.
    Crucial background material for this thesis also comes from
    the programming language design community of declarative programming
    languages.
    Prolog and its many extensions and dialects particularly stand out as
    fully-fledged logic programming languages, but parallels can also be drawn
    to querying languages that apply database techniques to static analysis.

    These different fields vary significantly in their interests, motivations,
    and approaches, but the underlying challenges are often similar.
    Notably, the performance of backtracking solvers and the scalability to
    complex problems are a recurring theme.

\subsection{Constraint Programming for Program Analysis}

    \paragraph*{Constraint analysis on abstract languages}
    Constraint systems have long been used for program analysis.
    \citet{Aiken:1999:ISC:339853.339897} gives a comprehensive overview of
    earlier work, highlighting the crucial ability of constraint-based program
    analysis to separate {\it constraint specification} from
    {\it constraint resolution}.
    This separation is critical also for this thesis, as it enables the
    scalability of compiler analysis problems beyond what could reasonably be
    implemented with manual recognition routines.
    The constraint specification can be formulated briefly, by offloading the
    {\it constraint resolution} to a separate solver.
    However, the article does not present any techniques to capture higher-level
    algorithmic concepts like computational idioms.
    Instead, it focuses on more basic compiler analysis problems, such as
    data flow analysis and type inference.

    More recent work on constraint-based program analysis by
    \citet{Gulwani:2008:PAC:1375581.1375616} leverages the advancements in
    modern off-the-shelf SAT/SMT solver technology.
    The analysis problems are lowered to bit-vector formulations, and the
    {\it constraint resolution} is entirely externalised to independently
    developed SMT solvers.
    The motivation of the approach is mainly to verify program properties,
    as opposed to the application of parallelising code transformation in this
    thesis.
    Furthermore, \Cref{sec:SATcomp} showed that the confinement to
    conventional SMT solvers is inefficient for the resolution of
    SSA constraint problems.

    \citet{Kundu:2009:POC:1543135.1542513} propose constraints to verify the
    correctness of program transformations with their system for
    Parameterized Equivalence Checking (PEC).
    This system improves on previous work performing translation validation.
    Translation validation is the validity checking of transformations on
    concrete input programs by comparing the semantics before and after
    modification.
    PEC implements a hybrid approach that allows some aspects of the program
    to be underspecified, yet does not check the soundness of transformations
    in full generality.
    The checking is done via a custom solver for the generated constraint
    problems.
    The hybrid nature allows the system also to validate program transformations
    that significantly modify the control flow, e.g.\ loop unswitching.
    However, it cannot discover transformation opportunities, only verify them
    after the transformation was applied.

    \paragraph*{Constraint analysis on compiler IR code}
    There is previous work on using constraint-based program analysis for real
    compiler intermediate representations, mostly in the area of security and
    the formal verification of software systems.
    This includes investigations into using SMT on LLVM intermediate
    representation, which is also used for the implementations in this thesis.
    \citet{Zhao:2012:FLI:2103656.2103709} built a model of LLVM IR for such
    solvers.
    However, this model serves an entirely different purpose to the SSA model
    of this thesis.
    The model provides operational semantics, but cannot be used to detect
    large-scale algorithmic structures in user programs, as is required for
    automatic heterogeneous acceleration.
    Instead, the focus is on formally verifying the correctness of existing
    compiler transformations for all possible user input.

    Recent domain-specific languages, such as Alive
    \citep{Lopes:2015:PCP:2737924.2737965}, operate on subsets of LLVM IR.
    The individual instructions are reformulated on bit-vectors, and the
    correctness of conditions is checked with an SMT solver.
    However, Alive only implements a subset of LLVM's integer and pointer
    arithmetic instructions.
    It has no support for control flow and does not scale to the applications
    that are used in this thesis for evaluation.
    Instead, it is designed for formally verifying already existing
    compiler optimisations that operate on only a handful of integer
    instructions at a time.
    Alive is meant to improve compilers, not user programs.

    LifeJacket \citep{Notzli:2016:LVP:2931021.2931024} proves the correctness of
    floating-point optimisations in LLVM, as does Alive-FP \citep{Menendez2016}.
    Both of these projects are extensions of the SMT-based Alive system.
    They extend the scope of the system to model a wider range of
    instructions as bit-vectors, enabling the verification of more compiler
    optimisations.
    LifeJacket and Alive-FP were successfully used to identify incorrectly
    implemented  optimising transformations in compilers.
    However, the fundamental limitations of Alive remain, and control flow is
    not supported.
    Therefore, only peephole optimisations can be evaluated by these approaches.

    The Alive-Infer system \citep{Menendez:2017:ADP:3062341.3062372} also builds
    on Alive but goes beyond the verification of existing compiler
    optimisations.
    The tool uses an SMT solver to automatically generate preconditions that
    need to hold for transformations to be applied.
    This moves the Alive system away from verifying optimisations and
    closer to automatically detecting algorithmic structure in parts of user
    programs.
    However, Alive-Infer still requires the separate specification of the actual
    transformation.
    It only generates additional conditions and does not handle control flow.

    \paragraph*{Constraint analysis on other program models}
    Other advanced approaches to extracting high-level code structures
    from programs that use constraints and verification systems have been
    proposed.
    \citet{Mendis2015Helium, Kamil2016Verified} suggest temporal logic as the
    foundation to formulate the necessary conditions for rephrasing
    well-structured Fortran and assembly code in restrictive models.
    These techniques leverage counter-example guided inductive synthesis to find
    provably correct translations into the high-level Halide language.
    The Halide compiler specialises the code again, exploring the
    optimisation space via powerful transformations that are enabled by its
    restrictive semantics.
    However, the focus is on a small class of computations, involving only
    dense memory access.
    This allows formal reasoning about correctness but is too restrictive for
    interesting computational idioms, such as sparse linear algebra.

    \citet{Mullen:2016:VPO:2908080.2908109} study low-level program
    transformations that are implemented for the formally verified CompCert
    compiler \citep{CompCert-ERTS-2018}, directly on x86 assembly.
    Instead of an automatic verification after modelling optimisations
    as SMT problems, the presented Peek system was checked with the interactive
    theorem prover Coq.
    This required approximately 30000 lines of manually written Coq code and
    proof lines.
    Some of the transformations consider rudimentary control flow constraints,
    but they cannot scale to computational idioms.

\subsection{Declarative Programming Languages for Program Analysis}

    \paragraph*{Languages for querying program properties}
    From the perspective of language design, the declarative programming
    languages Prolog and SQL are perhaps most influential.
    The two languages differ fundamentally.
    Prolog ("programmation en logique") is a logic programming language that
    originated in academia for analysing natural language
    \citep{Colmerauer:1993:BP:154766.155362}.
    By contrast, SQL ("Structured Query Language") was developed at IBM for
    managing data in relational database management systems
    \citep{Chamberlin:1974:SSE:800296.811515}.
    Nonetheless, specification languages for structures in program code have
    been designed taking inspiration from both backgrounds.

    The first such specification language was the Omega system by
    \citet{Linton:CSD-83-164}.
    It uses a relational database to store all the relevant properties of a
    program.
    The captured information is based on the abstract syntax tree of programs
    that are implemented in a subset of the Ada programming language.
    Additional edges are inserted to connect shared variables of
    successive expressions, given some indication of data flow between
    instructions.
    The system then allows database-style queries formulated in QUEL
    \citep{Stonebraker:1976:DII:320473.320476}, an SQL-style language.

    The CodeQuest system \citep{Hajiyev:2006:CSS:2171327.2171331} first combined
    the ideas of Omega and its database-oriented successors with the use
    of logic programming.
    The queries are translated into Datalog, a Prolog derivative that is
    implemented on top of SQL.
    This allows CodeQuest to be fundamentally more expressive, allowing
    recursive queries that are required for meaningful CFG inspection.
    Nonetheless, the approach is based on querying for source language features.
    This makes the detection of large-scale algorithmic structures in complex
    programming languages such as C++ infeasible, as demonstrated in
    \Cref{sec:syntacticmatching}.

    \paragraph*{Languages for generating compiler passes}
    Custom specification languages for generating compiler analysis and
    transformation passes have been presented in the literature.
    \citet{Martin1998} introduced a specification language for program analysis
    functionality called PAG, based on abstract interpretation.
    The generated functionality was integrated into C and Fortran compilers via
    a well-specified interface and applied successfully to real benchmark codes.
    However, the tool is focused on relatively simple compiler optimisations
    such as constant propagation.

    Domain-specific languages for compiler transformation passes were also
    studied by \citet{Olmos:2005:CSD:2136624.2136643}.
    The proposed Stratego system uses rewrite rules to apply tree
    transformations to the abstract syntax tree of source programs.
    However, this was only evaluated on the Octave language, and the general
    applicability on large-scale programs remains unclear.

    \citet{Lipps1989} designed the domain-specific language OPTRAN for matching
    patterns in attributed abstract syntax trees of Pascal programs.
    Semantically equivalent, more efficient implementations can then
    automatically replace the matching code patterns.
    With the focus on Pascal, it remains unclear how the proposed concepts
    translate to the complex C++ programs with pointer calculations that were
    used for the evaluation of this thesis.

    Another language for implementing compiler optimisations from
    declarative specifications is OPTIMIX \citep{Assmann1996,Assmann98optimix}.
    Similarly to the presented work in \Cref{chapter:candl}, OPTIMIX emphasises
    developer productivity.
    However, it is based on graph rewrite rules.
    OPTIMIX programs are compiled into C code that performs the specified
    transformation.
    Such a domain-specific language for the generation of optimisation
    transformations was also used in the CoSy compiler \citep{Alt1994}.
    Both OPTIMIX and the CoSy method are simple rewrite engines that have no
    knowledge of global program constraints.

    Different code transformation techniques use LibASTMatchers
    and LibTooling \citep{be0fa11ddb194bde86a9dab8589b779c} from the
    LLVM project.
    These tools do not provide a complete standalone language but are instead
    implemented in C++ as an embedded domain-specific language for pattern
    matching, relying heavily on other LLVM libraries.
    The approach is deeply integrated with the Clang compiler and exposes the
    abstract syntax tree (AST) of the compiler frontend directly.
    There are more than a thousand separate classes that implement types
    of AST nodes in Clang, introducing considerable complexity for any
    non-trivial pattern.
    Therefore, this is an entirely impractical approach for detecting complex
    algorithmic structures such as computational idioms.

    \citet{Willcock:2009:RGP:1621607.1621611} designed a complex system for
    generating generic optimisation passes using concepts from generic
    programming.
    However, such schemes do not work at the IR level of established
    compiler frameworks.
    Instead, they require program rewrites by the user.

    \citet{Whitfield:1997:AEC:267959.267960} praise Gospel, their framework and
    specification scripture for the exploration of the properties of
    code-improving transformations.
    The project furthermore includes the Genesis tool, which automatically
    generates transformers as specified in Gospel.
    Several standard optimisations were implemented with Gospel and Genesis,
    such as constant folding and common subexpression elimination.
    Similar approaches to generating compiler optimisations from specification
    languages include Rhodium \citep{Lerner:2005:ASP:1040305.1040335}.
    The language expresses optimisations using explicit data flow facts, which
    are manipulated by local propagation and transformation rules.
    The transformations are applied to a custom intermediate language and can
    be proven correct with a theorem prover.
    Neither Gospel nor Rhodium provides means to tackle the issue of efficiently
    enabling large-scale program transformations.

\section{Compiler Analysis and Auto-Parallelisation}

    The core motivation for the work in this thesis is the automatic
    heterogeneous parallelisation of sequential code.
    The derived methods are evaluated on two metrics: how broadly they apply to
    real code, and how significant their performance impact is when applied.
    These metrics are evaluated against other compiler analysis and
    parallelisation approaches.
    This section focuses on three areas of the vast research landscape
    that are particularly relevant for this: polyhedral compilation, the
    parallelisation of reductions, and dynamic approaches.

\subsection{Compilation with the Polyhedral Model}

    The polyhedral model \citep{Karp:1967:OCU:321406.321418} is an established
    mathematical framework for modelling, analysing, and transforming
    well-behaved loop nests.
    Iterations in loop nests are treated as lattice points in a
    multi-dimensional grid.
    The iteration space can then be transformed with affine maps, potentially
    uncovering new parallelisation opportunities.
    This basic approach has been applied extensively in compilers.
    Furthermore, the required conditions have been relaxed in different ways,
    allowing the application of the approach to more input code.

    \paragraph*{Polly in LLVM}
    Polyhedral optimisers have been integrated into mainstream C/C++ compilers.
    Most notably, \citet{Lengauer2012Polly} implemented the Polly extensions for
    LLVM.
    Polly recognises parts of LLVM IR that are expressible in the polyhedral
    model and transforms them into that representation.
    Polyhedral optimisations can then be applied with PLuTo
    \citep{Bondhugula:2008:PAP:1375581.1375595} before the model is
    translated back into optimised LLVM IR for further treatment by the core
    compiler.
    This enables the seamless application of polyhedral techniques on
    large-scale applications without source code changes via the many
    frontends of the LLVM infrastructure.
    However, this impacts only code that the tool can translate
    into a polyhedral representation.

    Polly-ACC \citep{polly-acc} is an extension of the Polly compiler that
    provides code generation for heterogeneous hardware.
    The tool uses the recognition functionality of standard Polly to detect
    code sections in LLVM IR that can be represented in the polyhedral model.
    These code sections are optimised with established polyhedral
    transformation techniques from \citet{Lengauer2012Polly}.
    However, the optimised polyhedral code sections are then translated into
    CUDA code to be executed on the GPU.
    This results in significant speedups of some benchmark programs, but the
    impact remains limited to code that fits the polyhedral model.

    \citet{Doerfert2015Polly} extended the applicability of polyhedral
    transformations within the Polly compiler to a broader set of input
    programs.
    Dependencies between iterations that originate from reduction variables
    cannot be eliminated with affine transformations.
    Therefore, they prohibit DOALL parallelism in a way that standard Polly is
    unable to resolve.
    However, the reduction-enabled scheduling approach for Polly can parallelise
    such loop despite the reduction dependencies.
    This ability significantly improved the achieved speedup of Polly on
    benchmark programs that contain reductions.

    \citet{Doerfert:2017:OLO:3049832.3049864} also investigated another method
    for widening the scope of polyhedral code transformations.
    This approach allows some conditions that are required for the legal
    application of transformations to remain unproven at compile time.
    These conditions are then checked at runtime, providing a fallback to the
    original code when assumptions are not met.
    The checks that this work allows to be delayed include the absence of
    aliasing, finite loop boundaries, and in-bounds memory accesses.
    This enabled Polly to cover 3.9$\times$ as many loops in the SPEC and NPB
    benchmarks at a negligible runtime overhead.

    \paragraph*{Other tools with automatic detection}
    The Polyhedral Parallel Code Generator (PPCG)
    \citep{Verdoolaege:2013:PPC:2400682.2400713} is a source-to-source compiler
    that takes sequential C programs and generates optimised CUDA kernels to
    target GPU acceleration.
    The extraction of polyhedral code sections from the C input is based on the
    Polyhedral Extraction Tool \citep{Verdoolaege12polyhedralextraction}.
    The extraction method can automatically detect relevant code regions, but it
    is implemented on syntax level and relies on purpose-built C code with all
    arrays declared in variable-length C99 array syntax.
    This is not robust enough to reliably cover larger programs from benchmark
    collections such as NPB or Parboil, which are used for evaluation in this
    thesis.

    C-to-CUDA \citep{Baskaran:2010:ACC:2175462.2175482} is another compiler that
    offers heterogeneous acceleration of sequential C code by representing it in
    the polyhedral model.
    However, the focus is on code generation and the application of optimising
    transformations.
    The automatic recognition in the abstract syntax tree of parallel loops that
    can be represented in the polyhedral model remains ad-hoc and handles only a
    small set of benchmarks.

    \paragraph*{Increased applicability of polyhedral transformations}
    Recent work by \citet{baghdadi2015PENCIL} has extended the polyhedral model
    beyond affine programs to some forms of sparsity with the
    Platform-Neutral Compute Intermediate Language (PENCIL).
    This intermediate language is intended for heterogeneous systems and
    provides backends for accelerator programming.
    This platform provides extensions, which can be used to model important
    features of sparse linear algebra, such as counted loops
    \citep{Zhao:2018:PCF:3178372.3179509}, meaning loops with dynamic, memory
    dependent bounds but statically known strides.
    Such loops are central to sparse linear algebra.

    Tiramisu \citep{Baghdadi:2019:TPC:3314872.3314896} is a polyhedral framework
    for targeting heterogeneous hardware, providing backends for CPUs, GPUs,
    distributed architectures and FPGAs.
    Optimisations are performed on four layers of intermediate representation,
    resulting in performance that almost matches dedicated library functions.
    However, the tool does not detect polyhedral code sections in existing
    source code.
    Instead, it requires the programmer to implement the algorithms manually
    with a dedicated C++ API.

    \citet{Zhang:2016:CTG:3018843.3018849} propose an extension to polyhedral
    approaches that allows the capturing of some sparse linear algebra
    calculations in the polyhedral model.
    They introduce a novel non-affine split transformation for this purpose.
    Using the inspector-executor model, the approach achieved significant
    speedup on some benchmark programs.
    However, the paper does not address the automatic recognition of sparse
    linear algebra routines within existing programs.
    Furthermore, the approach is not evaluated against state-of-the-art
    library implementations such as Intel MKL and cuSPARSE.

    Many approaches have been proposed for parallelising loop nests with
    reduction variables in the polyhedral model, among them
    \citet{jouvelot1989unified,redon1994scheduling,chi1997optimizing,
    gupta2006simplifying,stock2014framework}.

\subsection{Reduction Parallelism}

    Discovering and exploiting scalar reductions in programs has been studied
    for many years based on dependence analysis and idiom detection.
    Early work by
    \citet{pottenger1995idiom,suganuma1996detection,fisher1994parallelizing}
    focused on well-structured Fortran code and often paid little attention to
    robust detection in more complex programs.
    \citet{rauchwerger1999lrpd} went beyond previous static approaches and
    developed a dynamic test to speculatively exploit reduction parallelism.
    Work by
    \citet{Gutierrez:2000,gutierrez2003optimization,gutierrez2008analytical}
    has focused on the exploitation of reductions rather than discovery.
    Approaches to heterogeneous acceleration examined trade-offs in
    implementation \citep{yu2006adaptive} or exploitation of novel hardware
    \citep{ravi2010compiler,Huo2011HiPC}.

    The treatment of more general reduction operations has received less
    attention.
    \citet{das2010experiences} proposed dynamic profile analysis to guide
    manual analysis and show there is potential for finding generalised
    reductions.
    \citet{kim2012dynamic} explored the use of dynamic analysis further,
    but state that detecting reductions on arrays remains challenging.

    The difficulty in automatically detecting reductions has led to languages
    and annotation-based approaches, where it is the responsibility of the user
    to mark reductions in the program.
    Such a system was proposed by \citet{deitz2002high}.
    An annotation approach is also described by \citet{Reddy2016Reduction},
    based on the Platform-Neutral Compute Intermediate Language (PENCIL)
    \citep{baghdadi2015PENCIL}.
    This used the PPCG code generator by
    \citet{Verdoolaege:2013:PPC:2400682.2400713} to generate CUDA and OpenCL
    code for multiple computing platforms.

    There has also been recent work extending on \citet{rauchwerger1999lrpd}
    with more aggressive speculation and dynamic analysis
    \citep{aguilar2015unified} to exploit reduction parallelism.
    \citet{Han2010Speculative} present an approach for the
    parallelisation of a wide class of scalar reductions.
    They start from the observation that many reductions in real benchmark
    programs are not detected by current static analysis approaches.
    They propose a hardware-assisted speculative parallelisation approach for
    likely runtime reductions, denoted ``partial reduction variables''.
    Candidates for speculative parallelisation are determined by searching for
    update-chains in the data flow graph.
    The approach was evaluated on some of the SPEC2000 benchmarks using a
    simulator.
    They achieve up to $46\%$ speedup by including speculative reductions.
    However, this approach requires hardware speculation support.
    Despite this hardware support, it is unable to detect histogram reductions.

    Privateer \citep{Johnson:2012:SSP:2254064.2254107} is a complex system
    featuring compiler support and a runtime to enable speculative
    parallelisation.
    The core approach is the privatisation of memory for each thread and an
    exception mechanism with recovery routines for accesses that violate
    parallelism.
    The authors explicitly allow for reduction parallelism involving only a
    single scalar associative and commutative operator.
    The evaluation only covers a set of five benchmark programs, yielding
    a geometric mean speedup of 11.4x on a 24 core machine.
    The runtime overhead was up to $>50\%$.
    Despite this complexity, the approach only exploits simple scalar reductions.

\subsection{Dynamic Analysis Approaches}

    There is an extensive body of work on automated decision making for
    selecting the appropriate hardware for a given piece of code.
    This is often under the assumption that the functional porting is trivial,
    for example given an OpenCL implementation.
    These approaches are often based on dynamic monitoring of programs
    and machine learning algorithms for the selection of backends.

    \citet{Wen:2017:MSM:3038228.3038235} present a system for scheduling OpenCL
    kernels on a system with CPU and GPU processors, extending the approach
    presented in \citet{7116910}.
    The presented machine learning-based predictive model decides at runtime
    whether kernels are merged or executed separately on appropriate devices.
    However, such a system can only be applied when the functional translation
    to accelerators is available.
    This is not the case for the sequential C code that this thesis is evaluated
    on.
    Furthermore, the approach optimises OpenCL scheduling, but does not consider
    the impact of library backends, which often significantly outperform generic
    OpenCL implementations on appropriate tasks.

    \citet{Tournavitis:2009:THA:1542476.1542496} characterised the significant
    weaknesses of established static data dependence analysis techniques.
    Profile-driven parallelism detection and machine-learning based mapping
    approaches are suggested in order to improve on the state-of-art
    parallelising compilers.
    \citet{Wang:2014:IPP:2591460.2579561} implemented such a system that
    automatically discovers parallelism based on profile-driven parallelism
    detection.
    The approach improves significantly over purely static approaches by
    replacing the traditional target-specific and inflexible mapping heuristics
    with a prediction mechanism that uses machine learning.
    The model is trained via an offline supervised learning scheme, using both
    static and dynamic features, such as cache miss rates and branch miss
    prediction rate.
    Dynamic approaches can eliminate spurious dependencies and profitability
    models based on powerful machine learning techniques greatly improve on
    simple heuristics.
    However, such an approach cannot unlock the potential of dedicated backends
    and requires significant manual tuning effort.

    \citet{Ogilvie:2014:ALA:2628071.2628128} propose a system for performance
    prediction on heterogeneous systems that is based on active learning.
    This significantly reduces the tuning that is required for
    machine learning-based scheduling algorithms on CPU/GPU systems.
    However, this approach still requires the availability of functional mapping
    to heterogeneous devices, and cannot work on unchanged sequencial C/C++
    inputs.

    \citet{Manilov:2018:GPI:3178372.3179511} propose a dynamic approach to
    detecting a wide class of iterators using dynamic profiling data.
    Such iterators describe the traversal of data structures that are difficult
    to capture with tranditional static techniques.
    This is an important prerequisite for implementing compiler parallelisation
    approaches to pointer-based data structures.
    However, the approach only captures a small, if crucial, part of the
    calculations, and does not capture full computational idioms such
    as sparse linear algebra.

\section{Heterogeneous Computing}

    Heterogeneous computing has been a particularly active field of research
    since the widespread adoption of GPUs for general purpose computations in
    the last decade.
    This includes research from both software and hardware perspectives.
    The hardware research investigates the most promising directions of
    diversification for processors in heterogeneous systems
    \citep{Tomusk:2016:SHC:3012405.3014165}.

    However, the related work in the context of this research is from
    the software perspective.
    This section focuses on the different programming approaches that
    have been championed for targeting existing heterogeneous accelerators.
    These methods broadly fall into two categories: library approaches, and
    domain-specific languages.

\subsection{Libraries}

    Library interfaces are often the most performant ways to exploit
    heterogeneous performance.
    However, they provide narrow interfaces, accelerating only very particular
    computations.
    The established way of encapsulating fast linear algebra is via dedicated
    library implementations based on the BLAS interface specification
    \cite{2002:USB:567806.567807}.
    These are generally very fast on their specific hardware platforms, but
    require application programmer effort and offer little performance portability.
    Implementations of dense linear algebra are available for most suitable
    hardware platforms, such as cuBLAS \cite{cublas} for NVIDIA GPUs, clBLAS
    \cite{clblas} for AMD GPUs and the Intel MKL library \cite{mkl} for Intel
    CPUs and accelerators.

    Dense linear algebra is the best-supported class of calculations.
    However, implementations of sparse linear algebra also exist for
    the most important platforms, including cuSPARSE \cite{cusparse} for NVIDIA
    GPUs and clSPARSE \cite{clsparse} built on top of OpenCL.

    While most individual library implementations focus on a single target
    hardware platform, some BLAS implementations attempt platform independent
    acceleration and heterogeneous compute.
    Among them are systems by \citet{Wang:2016:BHP:2925426.2926256,
    10.1007/978-3-319-64203-1_33, Diego2017Multi}.

    More expressive computational idioms, such as reductions and stencils, are
    not suitable for library implementation.
    These idioms are parameterised with kernel functions, which can be
    implemented as callbacks, but prevent a direct execution on heterogeneous
    hardware.
    Instead, domain-specific languages provide the appropriate abstraction
    level for these computations.

    \paragraph*{CPU-GPU data transfer optimisations}
    Library implementations often require the manual management of CPU-GPU
    data transfers.
    These transfers have been studied extensively as important bottlenecks for
    parallelisation efforts.
    Work by \citet{Jablin:2011:ACC:1993316.1993516} established a
    method for the automatic management of CPU-GPU communication.
    Similarly, \citet{Lee:2009:OGC:1594835.1504194} implemented a system to
    optimising data transfers using data flow analysis, although this was in
    the context of moving OpenMP code to GPUs.

\subsection{Domain-Specific Languages}

    Many domain-specific languages have been proposed for the efficient and
    easy programming of heterogeneous systems.
    They allow implementers to restrict the compiler and runtime away from
    general purpose programming concepts that are difficult to support on
    specific hardware.
    Domain specific languages can be stand alone with an entire tool chain and
    runtime ecosystem of be embedded in existing languages, such as C++ or
    Scala.
    DSLs range in complexity from only marginally more flexible than library
    interfaces to full-fledged programming languages such as OpenCL and CUDA.

    \paragraph*{Functional languages}
    Lift \citep{steuwer15rewrite} provides composable constructs that enable the
    functional implementaion of data-parallel algorithms and operations.
    The language is especialy suitable for dense linear algebra applications
    \citep{Steuwer:2016:MMB:2968455.2968521} and stencil codes
    \citep{Hagedorn:2018:HPS:3179541.3168824}, but extensions to support
    some forms of sparsity exist as well
    \citep{Pizzuti:2019:PAA:3331553.3342614}.
    Lift performs optimisations by applying functional rewrite rules.
    This extensible set of rewrite rules allows the tool to cover a very large
    space of possible program transformations.
    However, selecting the best version from this large available configuration
    space requires guidance from profiling runs.
    Profiling runs can be computationally expensive, taking approximately
    one day to evaluate a sufficient number of variants for tuning the matrix
    multiplication kernel \citep{Steuwer:2016:MMB:2968455.2968521}.
    Such user effort can be prohibitive, but promises highly tuned OpenCL
    outputs.

    There exist multiple other functional approaches to generating code for
    heterogeneous hardware.
    Among them, \citet{chakravarty11accelerating,mcdonell13optimising} propose
    Accelerate, a domain-specific language that is embedded in Haskell.
    Accelerate applies sharing recovery and loop fusion optimisations to
    generates efficient GPU code.
    However, many of these techniques target particular challenges that arise
    from the untypical nature of Haskell, especially the methods for interfacing
    heterogeneous accelerators from a lazily evaluated environment.
    This makes Accelerate unsuitable for evaluation in this thesis, which
    focuses of benchmarks that are provided as C/C++ programs.


    Copperhead \citep{catanzaro11copperhead}, is a data parallel language
    embedded in Python.
    It exposes parallelism via higher-order functions such as {\it map},
    {\it gather}, and {\it reduce}.
    However, Copperhead is unable to compile the formulated programs into
    standalone binaries, leaving the programs tightly integrated in a Python
    environment.
    This makes the interface with C/C++ code nontrivial and is unsuitable for
    the acceleration of existing benchmarks in the evaluation of this thesis.

    \citet{collins14nova} introduced NOVA, a functional language targeted at
    code generation for GPUs.
    The evaluation showed comparable performance to dedicated library
    implementations on several important applications, including sparse
    matrix-vector multiplication.
    However, the work is highly focused on the generation of CUDA code and does
    not provide an OpenCL backend, which is crucial for evaluation on GPUs of
    multiple vendors.

    \paragraph*{Intermediate languages}
    Delite \citep{Sujeeth:2014:DCA:2601432.2584665} was presented as an
    intermediate representation that facilitates the rapid construction of
    domain-specific languages.
    The provided infrastructure targets heterogeneous
    platforms, with backends avaliable for OpenMP, CUDA, and even MPI for
    cluster computing.
    Delite-based DSLs are proposed for machine learning, data querying, graph
    analysis, and scientific computing.
    However, the Delite approach is tightly integrated with the Scala
    language and does not offer a readily available end-to-end solution.

    Halide, as proposed by \citet{Ragan-Kelley:2013:HLC:2499370.2462176}
    was designed for image processing, but is flexible enough to also allow the 
    formulation of matrix multiplications and other computations.
    \citet{Suriana:2017:PAR:3049832.3049863} demonstrates that this can extend
    to reduction computations as well.
    Its core design decision is the scheduling model that allows the separation
    of the computation schedule and the actual computation.
    There has been follow-up work on automatically tuning the schedules, e.g.\ 
    \citet{Mullapudi:2016:ASH:2897824.2925952}, but by default the burden of
    implementing efficient schedules is put on the application programmer.

    \paragraph*{Embedded languages}
    MILK \citep{Kiriansky:2016:OIM:2967938.2967948} is a pragma-based
    domain-specific language to annotate indirect memory accesses in C++.
    The approach is inspired by OpenMP, and are supported by modified versions
    of Clang and LLVM.
    This allows low level optimisations that are particularly applicable to
    sparse linear algebra.
    The authors report performance gains of up to 3x, but the approach is unable
    to utilise the much greater potential of heterogeneous compute and requires
    detailed programmer intervention.

    \paragraph*{Other approaches}
    Spatial \citep{Koeplinger:2018:SLC:3192366.3192379} is a domain-specific
    language for higher-level descriptions of application accelerators.
    The language provides hardware-centric abstractions, but also takes
    programmer productivity into consideration.
    However, the language does not target the most established heterogeneous
    CPU-GPU systems.
    Instead, the focus is on on Field Programmable Gate Arrays (FPGA) and
    Coarse Grain Reconfigurable Architectures (CGRA).
    This makes it unsuitable for comparative evaluation with the methods
    proposed in this thesis.

    There have been multiple domain-specific libraries proposed specifically
    for linear algebra computations.
    \citet{Spampinato:2014:BLA:2581122.2544155,
    Spampinato:2016:BLA:2854038.2854060} propose and extend the high-level
    language LGen for linear algebra, based on standard mathematical notation.
    The implemented routines are optimised with an autotuning compiler,
    exploring many transformations such as tiling, loop fusion, and
    vectorisation.
    The tool improves over Intel MKL on specific small-scale matrices, but is
    unable to generate code for GPUs.

    Recent research has highlighted the challenges of generating code that
    performs well on different heterogeneous hardware architectures.
    PetaBricks \citep{Ansel:2009:PLC:1542476.1542481,PhothilimthanaARA13} was
    one of the first languages to address this performance portability challenge
    by encoding algorithmic choices which are then empirically evaluated and
    automatically taken by the
    compiler.
    Similarly, \citet{MuralidharanRHG16} explored automatic selection of code
    variants using machine learning.

\section{Computational Idioms}

    The ideas behind the concept of {\it computational idioms} have been
    observed in different contexts.
    The basic observation is that software programs do not cover the
    space of possible programs evenly.
    Instead, they tend to be structured among certain design principles.
    This is true in particular for performance intensive programs and the
    core bottlenecks of large applications.

    The concrete concepts are partially overlapping and can be vague.
    Software design patterns are a way of understanding program code
    strucutres as specialised implementation of a class of standard approaches
    in the discipline of software engineering.
    Terms such as {\em map and reduce}, {\em stencil code}, and
    {\em linear algebra} are commonly used when designing libraries and
    domain-specific languages.
    Scientific computing is mostly concerned with the architectural
    implications of specific memory access patterns that are instrinsic to
    the choice of certain algorithmic approaches.
    This section apptempts to demarcate a meaningful conception of
    {\it computational idioms} by comparison with the existing literature of
    these different domains with related concepts.

\subsection{Higher-Order Functions}

    Many functional programming languages, such as OCaml and Haskell,
    encapsulate high-level algorithmic choices and common programming patterns
    as higher-order functions \citep{Hughes:1989:WFP:63410.63411}.
    These are functions that are parameterised with other functions.
    Examples of higher-order functions are {\it map}, which applies a function
    to each element in a data structure, and {\it fold} / {\it reduce}, which
    accumulates the elements in a data structure with a reduction operator.

    Common computational workloads can be expressed as instances of
    higher-order functions.
    For example, the popularity of the MapReduce framework
    \citep{Dean2008MapReduce} stems from the observation that many big data
    workloads exhibit characteristics that can be expressed efficiently with
    combinations of {\it map} and {\it reduce}.
    The framework provides an idiomatic approach to the development of big
    data applications, enabling shorter development times and more predictable
    performance.

    The use of computational idioms for automatic heterogeneous acceleration
    requires a more restrictive view of types than what is common in
    functional programming languages.
    For example, the {\it reduce} operator allows the implementation of
    the insertion sort algorithm, as well as a simple sum over an array of
    floating-point values.
    These two algorithms do not share parallelisation opportunities.
    Therefore, the detection of {\it reduce} instances is insufficient for
    enabling compiler parallelisation approaches.
    However, more restrictive versions of {\it reduce} are suitable for
    compiler detection.
    \Cref{chapter:reductions} studies in detail the class of Complex Reduction
    and Histogram Computations, which is formulated as a computational idiom.
    This restricted class of {\it reduce} calculations shares a common
    parallelisation approach.

\subsection{Parallel Dwarfs}

    The {\it Berkeley Dwarfs} are a collection of 13 computational methods
    that together comprise a large portion of the most common parallel computing
    workloads \citep{Asanovic06thelandscape}.
    Each Dwarf is a computational pattern that is common in important
    applications.
    The core observation of the authors is that the nature of the dwarfs has
    persisted more or less identical for many years, even as concrete
    applications changed.
    The Dwarfs are inspired by numerical computations that arise in the
    scientific computing community, although the authors claim that the
    knowledge from this domain may prove useful in other areas as well.

    The Berkeley Dwarfs are studied from the perspective of architecture
    requirements, not with automatic compiler support in mind.
    Therefore, some of the dwarfs are specified too broadly for use as
    computational idioms in this paper.
    However, dense linear algebra, sparse linear algebra, and strcutured grid
    computations (stencils) are important idioms in \Cref{chapter:idioms}.

\subsection{Algorithmic Skeletons}

    Another abstraction that relates to computational idioms as used in this
    thesis is the notion of Algorithmic Skeletons \citep{Cole1991Algorithmic}.
    This concept was introduced to classify the behaviour of parallel programs
    according to their organisation of workload distribution.
    The motivation of this approach was to enable the introduction of new,
    higher-level programming models and tools for parallel programming.
    Higher-order functions from functional programming were a major inspiration,
    observing a lack of similar abstractions on more mainstream programming
    languages.
    Among the Algorithmic Skeletons are Fixed Degree Divide \& Conquer and the
    Task Queue.

    The concept of Algorithmic Skeletons has been used to implement many
    programming frameworks and libraries.
    The eSkel library was sketched by \citet{Cole2004Bringing}, providing a
    higher-level programming model based on skeletons on top of C and MPI.
    Skandium \citep{Leyton2010Skandium} is a parallel skeleton library for
    multi-core architectures.
    Eden \citep{Loogen2005Parallel} provides skeletons for parallel programming
    in Haskell.
    SkelCL \citep{Steuwer2011SkelCL} provides implementations of algorithmic
    skeletons that target GPUs via CUDA.
    This is implemented in C++, providing templated versions of higher-order
    functions such as {\it map}, {\it reduce}, and {\it zip}.
    Finally, the Thread Building Blocks library
    \citep{Reinders2007Intel} implements Slgorithmic Skeletons.

    The definitions for Algorithmic Skeletons are not specified formally to
    enable automated reasoning, but are drafted for human understanding and to
    guide the design of libraries and DSLs.
    This abstraction level is similar to the Berkley Dwarfs.
    However, Algorithmi Skeletons were heavily inspired by higher-order
    functions and similarly describe the algorithmic structure of computations.
    This distinguishes them from the Berkeley Dwarfs, which are more focused on
    mathematical domains and architectural requirements.
