
    The thesis developed a constraint programming methodology that operates on
    SSA compiler intermediate representation.
    The Compiler Analysis Description Language (CAnDL) and the extended Idiom
    Description Language (IDL) were designed and implemented in the LLVM
    framework, making the constraint programming methodology available for
    program analysis.

    Several computational idioms were implemented in these languages, which
    enabled the automatic recognition of adhering user code sections during
    compilation.
    Among these idioms, stencils and different forms of both sparse and
    dense linear algebra are well-understood kernels.
    Complementing these established computational idioms, Complex Reduction and
    Histogram Computations (CReHCs) were introduced as a new grouping of
    computations.
    Evaluation on established benchmark suites NPB and Parboil demonstrated that
    each of these idioms covers significant performance bottlenecks.

    Recognising these computational idioms enabled generic compilers to apply
    idiom-specific optimising transformations, which are traditionally available
    only within domain-specific tools.
    Such transformations included the automatic parallelisation of programs that
    were inaccessible for previous analysis approaches.

    In the final chapter, the idiom detection functionality was applied to
    achieve the automatic heterogeneous parallelisation of sequential C/C++
    code.
    Idiomatic loops in user code were automatically redirected to
    domain-specific code generators, leveraging the domain knowledge that is
    available for code that is formulated in restrictive idioms.
    This approach was effective on 10 of the 21 benchmark programs from NPB and
    Parboil, resulting in significant speedups from 1.26$\times$  to 275$\times$
    against the sequential baseline versions.

    In summary, computational idioms were identified and confirmed as an
    effective interface to heterogeneous acceleration, and the methodology
    for automatically recognising such idioms via constraint programming was
    derived.
    Main contributions are the methodology of constraint programming on SSA
    intermediate representation; the design and implementation of CAnDL and IDL;
    and the identification of CReHCs as a significant class of benchmark
    bottlenecks.

\section{Contributions}

\subsection{Constraint Programming on SSA Code}

    \Cref{chapter:theory} introduced an approach for applying constraint
    programming to SSA intermediate representation code.
    Based on a model of the static structure of SSA programs, SSA constraint
    problems were defined.
    These are formulas that impose restrictions on compiler intermediate code,
    turning the detection of adhering program parts into a constraint problem.
    The chapter then derived efficient algorithms for solving SSA constraint
    problems and discussed several significant types of constraint formulas.
    These reflected compiler analysis methods like data flow and dominance
    relationships.
    The methodology was derived from algebraic formulation all the way to
    specific implementation considerations, is transferrable to any SSA
    intermediate representation, and can express a wide range of important
    compiler analysis problems.

\subsection{CAnDL and IDL}

    \Cref{chapter:candl,chapter:reductions} designed and implemented two
    custom declarative programming languages: The Compiler Analysis
    Description Language (CAnDL) and the extended Idiom Description Langauge
    (IDL).
    These languages make the constraint programming methodology directly
    available in the LLVM framework.
    This enables the previously derived approach to operate or real user code,
    directly from within the state-of-the-art Clang C/C++ compiler.

\subsection{Complex Reduction and Histogram Computations}

    Complex Reduction and Histogram Computations (CReHCs) were introduced in
    \Cref{chapter:reductions} as a computational idiom.
    CReHCs are a generalisation of well-understood scalar reductions that
    encompasses indirect array accesses as typical in calculations of
    histograms.
    This class of loops was not previously studied as one unit, but the
    chapter showed that shared parallelisation opportunities exist.
    Furthermore, an evaluation of established benchmark suites demonstrated
    that significant performance bottlenecks in each of NPB, Parboil, and
    Rodinia are CReHCs.

\subsection{Formulation of Idioms}

    \Cref{chapter:candl,chapter:reductions,chapter:idioms} formulated a range of
    different computational idioms in CAnDL and IDL.
    These idioms included stencils, different forms of sparse and dense linear
    algebra, Static Control Parts (SCoPs), and CReHCs.
    This enabled the automatic recognition of higher-level structure during
    compilation.

\subsection{Heterogeneous Acceleration Pipeline}

    \Cref{chapter:idioms}

\section{Critical Analysis}

    Several iddues remain with the work.
    Only a finite number of variables.
    Programs difficult to debug.
    SSA model needs to be reconstructed whenever acting on the results.

\subsection{Generality of Computational Idioms}    

\subsection{Compile Time Cost}

\subsection{Finite Varaiable Numbers}

    The most visually apparent imperfection of both CAnDL and IDL is the
    limitation to a finite amount of variables in the underlying constraint
    problem.
    This results in upper bounds for the number of features in almost all idioms
    that have no fundamental justification:
    CReHCs can only contain a maximum of two histograms, stencil codes can only
    use a neighbourhood of up to 32 items, and so on.
    In practice, this involves a tradeoff between performance and the genreality
    of the idiom specification, as each additional variable introduces a slight
    overhead for the solver.

    Similar problems are well-known in other research disciplines that involve
    an underlying solver.
    Most prominently, bounded model checking techniques are built on SMT solvers
    with the same limitation.
    The same solution could be applied to IDL: Just repeatedly run the solver
    with more and more variables, up to a certain boundary.
    That way easy solutions are quickly found, but difficult solutions are not
    discarded entirely.

\subsection{Acting on Solutions Invalidates SSA Model}

\pagebreak
\section{Future Work}

    Future work will focus on extending the approach to pointer-intensive
    idioms, improving the usability of specification, and complementing
    the static approaches with established dynamic techniques.

\subsection{Additional Idioms}

    The ability to express sparse linear algebra sets the detection ability of
    constraint programming on compiler immediate representation apart from
    previous approaches, involving the polyhedral model or data-flow analysis.
    Going beyond sparse data access, IDL could be used to formulate data access
    patters that involve pointer chases.
    This would enable it to detect graph operations, such as depth-first search
    and the PageRank algorithm.
    Furthermore, this approach could detect list traversal, insertion, and
    removal of elements.
    Such operations are not typically performance critical, but could be a first
    step to a deeper semantic understanding of programs in compilers.

\subsection{Simplify Specification Languages}

    The specification languages CAnDL and IDL enable the detection of
    sophisticated computational idioms, but profound knowledge of compilers is
    required to sucessfully write correct specifications. 
    Furthermore, the presented specifications are almost entirely independent of
    the specific underlying intermediate representation LLVM IR.
    However, the precise extent of this independence left unclear.

    Future work will investigate higher-level languages that abstract away the
    IR-specific nature of CAnDL and IDL, and provide a more streamlined
    programming experience.
    The pseudocode and corresponding IDL specifications in
    \Cref{csr_lilacwhat_fig,jds_lilacwhat_fig} in \Cref{chapter:idioms} already
    suggest how this can be achieved:
    For many restricted domains (in that case SPMV), generating IDL code from
    high-level expressions is straightforward.

\subsection{Complementing Dynamic Approaches}

    Several shortcomings of the presented approaches could be alleviated with
    dynamic approaches that complement the entirely static nature of constraint
    programming on compiler immediate representation.

    Dynamic analysis could be used to preselect candidate loops, drastically
    reducing the compile time overhead.
    Dynamic methods are required to efficiently transfer memory between
    heterogeneous participants, and to rule out pointer aliasing.

\subsection{Generating Specifications by Example}

    Specification could be generated from example.
